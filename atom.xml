<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>图灵先生的光</title>
  
  <subtitle>stay hungry, stay foolish.</subtitle>
  <link href="https://itachicheng.github.io/atom.xml" rel="self"/>
  
  <link href="https://itachicheng.github.io/"/>
  <updated>2025-08-05T02:12:58.586Z</updated>
  <id>https://itachicheng.github.io/</id>
  
  <author>
    <name>ChengQiang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Depth-First-Search</title>
    <link href="https://itachicheng.github.io/Depth-First-Search/"/>
    <id>https://itachicheng.github.io/Depth-First-Search/</id>
    <published>2025-08-05T01:46:24.000Z</published>
    <updated>2025-08-05T02:12:58.586Z</updated>
    
    <content type="html"><![CDATA[<p><img src="Depth-First-Search/image-20250805095815972.png" alt="image-20250805095815972"></p><p><img src="Depth-First-Search/image-20250805100428837.png" alt="image-20250805100428837"></p><p><img src="Depth-First-Search/image-20250805101123102.png" alt="image-20250805101123102"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;Depth-First-Search/image-20250805095815972.png&quot; alt=&quot;image-20250805095815972&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Depth-First-Search/image-202508</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Diffusion-Model</title>
    <link href="https://itachicheng.github.io/Diffusion-Model/"/>
    <id>https://itachicheng.github.io/Diffusion-Model/</id>
    <published>2025-06-06T14:39:51.000Z</published>
    <updated>2025-08-04T06:37:39.026Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Diffusion-Model">Diffusion Model</h3><h4 id="Application">Application</h4><ul><li><p>Stability AI’s Stable Diffusion</p></li><li><p>OpenAI’s DALL-E(beginning with DALL-E-2)</p></li><li><p>Midjourney</p></li><li><p>Google’s Imagen</p></li></ul><p>They improve upon the performance and stability of other <a href="https://www.ibm.com/topics/machine-learning">machine learning</a> architectures used for image synthesis such as <a href="https://www.ibm.com/think/topics/variational-autoencoder">variational autoencoders (VAEs),</a> generative adversarial networks (GANs) and autoregressive models such as PixelCNN.</p><p>Diffusion models are most prominently associated with image generation and other image processing tasks such as inpainting and super-resolution, but their applications extend to other domains including audio generation, drug design and molecule generation. For simplicity, this article will focus on image generation.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Diffusion-Model&quot;&gt;Diffusion Model&lt;/h3&gt;
&lt;h4 id=&quot;Application&quot;&gt;Application&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Stability AI’s Stable Diffusion&lt;/p&gt;
&lt;/li&gt;
&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Ascend</title>
    <link href="https://itachicheng.github.io/Ascend/"/>
    <id>https://itachicheng.github.io/Ascend/</id>
    <published>2025-05-29T15:40:00.000Z</published>
    <updated>2025-08-04T06:37:39.021Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Host与Device">Host与Device</h3><ul><li>Host指与Device相连的X86服务器、ARM服务器，会利用Device提供的NN（Neural Network）计算能力完成任务</li><li>Device模块指安装了昇腾AI处理器的硬件设备，利用PCIe接口与Host侧连接，提供NN计算能力</li></ul><h3 id="核函数">核函数</h3><p>核函数（Kernel Function）是Ascend C算子device侧的入口。Ascend C允许用户使用核函数这种C/C++的语法扩展来运行device代码。用户在核函数中实现算子逻辑的编写，例如自定义算子类及其成员函数以实现该算子的所有功能。</p><p><strong>核函数</strong>是直接在device侧执行的代码。在核函数中，需要为在一个核上执行的代码规定要进行的<strong>数据访问</strong>和<strong>计算操作</strong>，SPMD编程模型允许核函数调用时，多个核并行地执行同一个计算任务。</p><p>核函数是host侧和device侧连接的桥梁。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Ascend C __global__ __aicore__ <span class="keyword">void</span> <span class="title">kernel_name</span><span class="params">(argument list)</span></span>;</span><br><span class="line"><span class="function">CUDA __global__ <span class="keyword">void</span> <span class="title">kernel_name</span><span class="params">(argument list)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="DaVinci-Core">DaVinci Core</h3><h3 id="AI-Core的逻辑架构抽象">AI Core的逻辑架构抽象</h3><ul><li><p>计算单元</p><p>AI Core内异步计算过程（指令流）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">标量计算单元:读取指令序列 --&gt; 标量计算单元:发射指令到对应单元 --&gt; 各处理单元:并行执行指令:数据搬运,向量计算,矩阵计算</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>存储单元</p><ul><li>Local Memory: AI Core上的所有存储，这里的Local本地，指的是AI Core的内部；</li><li>Global Memory: 无论是DDR|HBM|L2 级缓存|内存，Global指AI Core外部的存储；</li></ul></li><li><p>搬运单元</p><p>AI Core内部搬运过程（数据流）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">DMA:数据搬入LocalMem --&gt; 计算单元:数据完成计算,回写LocalMem --&gt; DMA:数据搬出到GlobalMem</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="AI-Core内部并行计算架构抽象">AI Core内部并行计算架构抽象</h3><ul><li><p>计算单元</p><p>Scalar计算单元：执行地址计算、循环控制等标量计算工作，并把向量计算、矩阵计算、数据搬运、同步指令发射给对应单元执行</p><p>Cube计算单元：负责执行矩阵计算</p><p>Vector计算单元：负责执行向量计算</p></li><li><p>搬运单元</p><p>负责在Global Memory和Local Memory之间搬运数据</p><p>MTE1——数据在AI Core内部的流转</p><p>MTE2——数据搬入单元</p><p>MTE3——数据搬出单元</p></li><li><p>存储单元</p><p>编程对象，数据主体</p><p>外部存储：Global Memory</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">(__gm__ uint8 *__restrict__ src_gm, __gm__ <span class="keyword">uint8_t</span> *__restrict__ dst_gm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">uint32_t</span> dataSize = <span class="number">256</span>;</span><br><span class="line">  GlobalTensor&lt;<span class="keyword">int32_t</span>&gt; inputGlobal;<span class="comment">// 类型为int32_t</span></span><br><span class="line">  <span class="comment">// 设置源操作数在Global Memory上的起始地址为src_gm,所占外部存储的大小为256个int32_t</span></span><br><span class="line">  inputGlobal.<span class="built_in">SetGlobalBuffer</span>(<span class="keyword">reinterpret_cast</span>&lt;__gm__ <span class="keyword">int32_t</span> *&gt;(src_gm), dataSize);</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内部存储：Local Memory</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="class"><span class="keyword">class</span> <span class="title">LocalTensor</span> &#123;</span></span><br><span class="line">  <span class="function">T <span class="title">GetValue</span><span class="params">(<span class="keyword">const</span> <span class="keyword">uint32_t</span> offset)</span> <span class="keyword">const</span></span>; <span class="comment">// 获取LocalTensor中的某个值，返回T类型的立即数。</span></span><br><span class="line">  <span class="comment">// 获取距原LocalTensor起始地址偏移量为offset的新LocalTensor，注意offset不能超过原有LocalTensor的size大小。offset单位为element</span></span><br><span class="line">  LocalTensor <span class="keyword">operator</span>[](<span class="keyword">const</span> <span class="keyword">uint32_t</span> offset) <span class="keyword">const</span>;</span><br><span class="line">  <span class="function"><span class="keyword">uint32_t</span> <span class="title">GetSize</span><span class="params">()</span> <span class="keyword">const</span></span>; <span class="comment">// 获取当前LocalTensor size大小</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>LocalTensor指代的是AI Core内部的存储，不同的流水任务之间存在数据依赖，需要进行数据传递。Ascend C中使用Queue队列完成任务之间的数据通信和同步，例如在Compute之前完成CopyIn的数据搬运。</p></li></ul><h3 id="逻辑位置">逻辑位置</h3><table><thead><tr><th>TPosition</th><th>具体含义</th></tr></thead><tbody><tr><td>GM</td><td>Global Memory，对应AI Core的外部存储</td></tr><tr><td>VECIN</td><td>用于向量计算，搬入数据的存放位置，在数据搬入Vector计算单元时使用此位置</td></tr><tr><td>VECOUT</td><td>用于向量计算，搬出数据的存放位置，在将Vector计算单元结果搬出时使用此位置</td></tr><tr><td>A1</td><td>用于矩阵计算，存放整块A矩阵，可类比CPU多级缓存中的二级缓存</td></tr><tr><td>B1</td><td>用于矩阵计算，存放整块B矩阵，可类比CPU多级缓存中的二级缓存</td></tr><tr><td>A2</td><td>用于矩阵计算，存放切分后的小块A矩阵，可类比CPU多级缓存中的一级缓存</td></tr><tr><td>B2</td><td>用于矩阵计算，存放切分后的小块B矩阵，可类比CPU多级缓存中的一级缓存</td></tr><tr><td>CO1</td><td>用于矩阵计算，存放小块结果C矩阵，可理解为Cube Out</td></tr><tr><td>CO2</td><td>用于矩阵计算，存放整块结果C矩阵，可理解为Cube Out</td></tr></tbody></table><h3 id="开发流程">开发流程</h3><p>算子分析：分析算子的数学表达式、输入、输出以及计算逻辑的实现，明确需要调用的Ascend C接口。</p><ul><li><p>明确算子的数学表达式及计算逻辑</p><p>Add算子的数学表达式： $$z = x + y$$ ，计算逻辑：输入数据需要先搬入到片上存储，然后使用计算接口完成两个加法运算，得到最终结果，再搬出到外部存储</p></li><li><p>明确输入和输出</p><p>Add算子有两个输入： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 与 $$y$$ ，输出为 $$z$$ 。输入数据类型为half，输出数据类型与输入数据类型相同。输入支持固定shape（8，2048），输出shape与输入shape相同。输入数据排布类型为ND。</p></li><li><p>确定核函数名称和参数</p><p>自定义核函数名，如add_custom。</p></li><li><p>确定算子实现所需接口</p><p>DataCopy实现</p><p>Add双目实现</p><p>使用到LocalTensor，使用Queue队列管理，会使用到EnQue，DeQue接口。</p></li></ul><p>核函数定义：定义Ascend C算子入口函数</p><p>根据编程范式实现算子类：完成核函数的内部实现</p><h3 id="编程范式">编程范式</h3><p>Ascend C编程范式把算子内部的处理程序，分成多个流水任务（Stage），以张量（Tensor）为数据载体，以队列（Queue）进行任务之间的通信同步，以内存管理模块（Pipe）管理任务间的通信内存。</p><h3 id="SPMD模型">SPMD模型</h3><p>Ascend C算子编程是SPMD的编程，将需要处理的数据拆分并分布在多个计算核心上运行</p><p>多个AI Core共享相同的指令代码，每个核上的运行实例唯一的区别是block_idx不同</p><p>block的类似于进程，block_idx就是标识进程唯一性的进程ID，编程中使用函数GetBlockIdx()获取ID</p><h3 id="流水任务">流水任务</h3><p>单核处理程序中主程序调度的并行任务。在核函数内部，可以通过流水任务实现数据的并行处理来提升性能。</p><h3 id="矢量编程流水任务设计">矢量编程流水任务设计</h3><p>矢量算子编程范式把算子的实现分为3个基本任务：CopyIn，Compute，CopyOut。</p><p>CopyIn，Compute任务间通过VECIN队列inQueueX，inQueueY进行通信和同步，Compute，CopyOut任务间通过VECOUT队列outQueueZ进行通信和同步。</p><p>pipe内存管理对象对任务间交互使用到的内存，临时变量使用到的内存统一进行管理。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KernelAdd</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Init</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Process</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">CopyIn</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Compute</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">CopyOut</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX, inQueueY;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    GlobalTensor&lt;half&gt; xGm, yGm, xGm;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Init-函数实现">Init()函数实现</h3><p>使用多核并行计算，需要将数据切片，获取到每个核实际需要处理的在Global Memory上的内存偏移地址.</p><p>数据整体长度TOTAL_LENGTH为8 * 2048，平均分配到8个核上运行，每个核上处理的数据大小BLOCK_LENGTH为2048，block_idx为核的逻辑ID，x + block_idx * BLOCK_LENGTH，索引为block_idx的核的输入数据在Global Memory上的内存偏移地址。</p><p>对于单核处理数据（2048个数字进行进一步切分，一条向量计算指令，它的计算容量是有限的，Vector是256个字节），可以进行数据切块（Tiling），将数据切分成8块。切分后的每个数据再次切分成BUFFER_NUM=2块，可以开启double buffer,实现流水之间的并行。</p><p>单核需要处理的2048个数据切分成16块，每块TILE_LENGTH=128个数据。Pipe为inQueueX分配了BUFFER_NUM块大小为TILE_LENGTH * sizeof(half)个字节的内存块，每个内存块能容纳TILE_LENGTH=128个half类型数据。</p><h3 id="CopyIn-函数实现">CopyIn()函数实现</h3><h3 id="Compute-函数实现">Compute()函数实现</h3><h3 id="CopyOut-函数实现">CopyOut()函数实现</h3><h3 id="Host侧算子实现">Host侧算子实现</h3><p>host侧算子实现开发包括Tiling实现、Shape推导等函数实现、算子原型注册：</p><ol><li><p>Tiling实现（TilingFunc），计算数据切分过程相关的参数，比如每次计算的数据量大小</p><p>（Vector计算单元一次只能处理256Byte，Cube计算单元一次只能处理16 * 16矩阵的计算）</p></li><li><p>Shape推导等函数实现（InferShape），根据算子的输入张量描述、算子逻辑及算子属性，推理出算子的输出张量描述，包括张量的Shape、数据类型及数据排布格式等信息。这样算子在构图准备阶段就可以为所有的张量静态分配内存，避免动态内存分配带来的开销。</p></li><li><p>算子原型注册（OpDef），除了上述函数的开发，还需要进行算子原型定义，原型定义描述了算子的输入输出，属性等信息以及算子在AI处理器上相关实现信息，算子原型注册会关联算子原型定义和上述Tiling实现、Shape推导等函数，将其组合成一个整体。</p></li><li><p>算子类注册（OP_ADD）</p></li></ol><h3 id="Tiling下发">Tiling下发</h3><p>大多数情况下，Local Memory的存储，无法完全容纳算子的输入与输出的所有数据，需要每次搬运一部分输入数据进行计算然后搬出，再搬运下一部分输入数据进行计算，直到得到完整的最终结果，这个数据切分，分块计算的过程称之为Tiling实现。</p><ul><li>每次搬运的那一部分数据块，叫做Tiling块</li><li>根据算子中不同输入形状确定搬入基本块大小的相关算法，叫做Tiling算法（或Tiling策略）</li><li>承载Tiling策略信息的数据结构叫做Tiling结构体</li><li>算子中实现Tiling算法并将Tiling结构体下发给Kernel侧的函数（一般定义在host侧的host实现文件中），叫做Tiling函数（或Tiling Function）</li><li>Tiling实现完成后，获取到的Tiling切分算法相关参数，会传递给kernel侧，用于指导并行数据的切分。由于Tiling实现中完成的均为标量计算，AI Core并不擅长，所以我们将其独立出来放在Host侧 CPU上进行。</li></ul><h3 id="Tiling函数">Tiling函数</h3><ul><li>定义完Tiling结构体之后，即可着手实现Tiling函数，即尝试根据算子输入输出的shape等信息推算出Tiling信息，保存到Tiling结构体中，下发给Kernel侧。</li><li>Tiling函数的入参和出参是同一个对象，即TilingContext对象，Tiling结构体保存在这个对象中，运行时环境会自动将此对象从Host侧传递给Kernel侧。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">获取TilingContext上下文:Tiling函数的入参 --&gt; 通过上下文获取输入输出的Shape信息 --&gt; 根据Shape信息设置TilingData,序列化TilingData并保存至TilingContext --&gt; 设置block_dim --&gt; 设置TilingKey --&gt; 设置workspace_size</span><br></pre></td></tr></table></figure><p>根据数据的尺寸设置不同的TilingKey，来选择不同的Tiling策略，同时软件栈在编译的时候会选择对应TilingKey的代码进行编译，节约空间。</p><p>将Tiling塞到context中实际上调用的就是<code>tiling.SavetoBuffer</code>，这样device侧就可以拿到tiling信息了。</p><h3 id="Kernel侧使用Tiling信息">Kernel侧使用Tiling信息</h3><p>kernel侧需要接受Tiling信息时，核函数定义是这样的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ __aicore__ <span class="keyword">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里参数的顺序按照“输入、输出、workspace、tiling”的顺序排布，开发者不要调整其顺序。</p><p>用GET_TILING_DATA来拆箱，第一个参数“tiling_data”名字随便取。</p><p>workspace表示在Global Memory上申请的额外空间。</p><h3 id="Shape推导概述">Shape推导概述</h3><p>根据输入Tensor得到输出Tensor就可以完成网络的运行，但在实际的网络模型生成过程中，会先进行Tensor Shape以及data type的推导。这样可以让我们在图执行之前，就知道Tensor的数据类型和形状，提前校验其正确性；</p><p>同时提前推理出算子的输出张量描述，包括张量的形状，数据类型以及数据排布格式等信息，算子构图准备阶段就可以为所有的张量静态分配内存，避免动态内存分配带来的开销。</p><h3 id="计算类API">计算类API</h3><p>包括标量计算API、向量计算API、矩阵计算API，分别实现调用Scalar计算单元、Vector计算单元、Cube计算单元执行计算的功能。</p><h3 id="CPU域精细调试手段：单步调试——GDB">CPU域精细调试手段：单步调试——GDB</h3><p>可使用gdb单步调试算子计算精度。由于cpu调测已转为多进程调试，每个核都会拉起独立的子进程，故gdb需要转换成子进程调试的方式。针对Atlas 推理系列产品、Atlas 训练系列产品，每个核会拉起1个子进程，针对Atlas A2训练系列产品，每个核会拉起3个子进程，1个Cube，2个Vector。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 单独调试一个子进程</span></span><br><span class="line">set follow-fork-mode child </span><br></pre></td></tr></table></figure><h3 id="NPU域调试">NPU域调试</h3><h4 id="针对标量">针对标量</h4><p>在代码中直接编写AscendC::printf(…)来观察数值输出。样例代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AscendC::<span class="built_in">printf</span>(<span class="string">&quot;xLocal size: %d\n&quot;</span>, xLocal.<span class="built_in">GetSize</span>())</span><br></pre></td></tr></table></figure><ul><li><p>整个Tensor参与计算</p></li><li><p>Tensor前n个数据计算</p></li><li><p>Tensor高维切分计算</p><p>功能灵活的计算API，充分发挥硬件优势，支持对每个操作数的Repeat times(迭代的次数)、Block stride（单次迭代内不同block间地址步长）、Repeat stride（相邻迭代间相同block的地址步长）、Mask（用于控制参与运算的计算单元）的操作。</p><ul><li>Repeat times(迭代的次数)</li></ul></li></ul><h3 id="数据搬运API">数据搬运API</h3><p>计算API基于Local Memory数据进行计算，所以数据需要先从Global Memory搬运至Local Memory，再使用计算API完成计算，最后从Local Memory搬出至Global Memory。比如DataCopy接口。</p><h3 id="内存管理API">内存管理API</h3><p>用于分配管理内存，比如AllocTensor、FreeTensor接口。任务间数据传递使用到的内存统一由<strong>内存管理模块Pipe</strong>进行管理。</p><p><strong>Pipe</strong>作为片上内存管理者，通过InitBuffer接口对外提供Queue内存初始化功能，开发者可以通过该接口为指定的<strong>Queue</strong>分配内存。</p><p>Queue队列内存初始化完成后，需要使用内存时，通过调用<strong>AllocTensor</strong>来为<strong>LocalTensor</strong>分配内存给<strong>Tensor</strong>，当创建的<strong>LocalTensor</strong>完成相关计算无需再使用时，再调用<strong>FreeTensor</strong>来回收<strong>LocalTensor</strong>的内存。</p><p>TQue是队列，对应的TPosition是VECIN，VECOUT，TBuf是缓冲（管理中间变量），对应的TPosition是VECCAL。</p><p>TBuf占用的存储空间通过TPipe进行管理，您可以通过<a href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>接口为TBuf进行内存初始化操作，之后即可通过<a href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0163.html">Get</a>获取指定长度的Tensor参与计算。</p><p><strong>使用<a href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>为TBuf分配内存和为Queue分配内存有以下差异</strong>：</p><ul><li>为TBuf分配的内存空间只能参与计算，无法执行Queue队列的入队出队操作。</li><li>调用一次内存初始化接口，TPipe只会为TBuf分配一块内存，为Queue队列可以通过参数设置申请多块内存。如果要使用多个临时变量，需要定义多个TBuf数据结构，对每个TBuf数据结构分别调用<a href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>接口进行内存初始化。</li><li>TBuf获取的Tensor无需释放。</li></ul><h3 id="任务同步API">任务同步API</h3><p>完成任务间的通信和同步，比如EnQue、DeQue接口。不同的API指令间有可能存在依赖关系，从硬件架构抽象可知，不同的指令异步并行执行，为了保证不同指令队列间的指令按照正确的逻辑关系执行，需要向不同的组件发送同步指令。同步控制API内部即完成这个发送同步指令的过程，开发者无需关注内部实现逻辑，使用简单的API接口即可完成。</p><h3 id="算子调用">算子调用</h3><ul><li><h6 id="Kernel直调">Kernel直调</h6><p>NPU侧运行比CPU侧多了Host侧到Device侧拷贝的代码，同时，ACLRT_LAUNCH_KERNEL是异步的，需要aclrtStrem stream来进行管理。</p></li><li><h6 id="AscendCL单算子调用">AscendCL单算子调用</h6><ul><li><p>单算子API执行（aclnn）:基于C语言的API执行算子，直接调用单算子API。多用于大模型训练算子，即整网算子模型较为固定的场景。</p><p>aclnnXxxGetWorkspaceSize(const aclTensor *src, …, aclTensor *out，uint64_t workspaceSize，aclOpExecutor **executor);</p><p>workspaceSize：工作空间 aclMalloc</p></li><li><p>单算子模型执行：基于图模式执行算子，先编译算子（例如，使用ATC工具将Ascend IR定义的单算子描述文件编译成算子om模型文件），再调用AscendCL接口加载算子模型，最后调用AscendCL接口执行算子。多用于搜广推，整网模型变化较大的场景。</p></li><li><p>Pytorch算子调用</p><p>Pytorch的适配流程，主要包括两个步骤：<strong>算子注册分发</strong>和<strong>适配插件实现</strong>。</p></li></ul></li></ul><h3 id="源码编译-二进制编译">源码编译/二进制编译</h3><ul><li><p>二进制编译</p><p>对算子kernel侧实现进行编译，生成描述算子相关文件的json文件*.json和算子二进制 *.o。如果需要直接调用算子二进制，则使用该编译方式</p></li><li><p>源码编译</p><p>不对算子kernel侧实现进行编译，保留算子kernel源码文件 *.cpp。该方式可以支持算子的在线编译、通过ATC模型转换的方式编译算子的场景。</p></li></ul><h3 id="形状为（1-660）的half类型输入数据，利用4核完成add计算">形状为（1,660）的half类型输入数据，利用4核完成add计算</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>1</mn><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mo>=</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">1 block = 32 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">1</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">32</span></span></span></span></span></p><h4 id="处理步骤1-32字节对齐">处理步骤1: 32字节对齐</h4><p>Add的输入shape为（1，660），数据类型为half，当前输入无法对齐到一个block的大小（32B），首先需要进行数据补齐。</p><h4 id="处理步骤2：按照核数（本次是4核）进行核间数据拆分">处理步骤2：按照核数（本次是4核）进行核间数据拆分</h4><p>上一步将输入数据，补齐为42个32B的数据块，本步骤需要将这些数据分配到4个核上进行计算，每个核上分得的数据块数量不一致。</p><h4 id="处理步骤3：根据UB限制进行核内数据分批计算">处理步骤3：根据UB限制进行核内数据分批计算</h4><p>针对单核计算，计算核一次能够处理的数据受到UB大小的限制，因此需要根据UB大小将每个核需要处理的数据进行批次拆分。假设本次计算UB大小是1536B。</p><h3 id="开发环境">开发环境</h3><ul><li><p>非昇腾AI设备</p><p>代码开发、编译等不依赖昇腾设备的开发环境</p></li><li><p>昇腾AI设备</p><p>支持代码开发和编译，同时可以运行应用程序或进行训练脚本的迁移、开发&amp;调试</p></li></ul><h3 id="运行环境">运行环境</h3><ul><li><p>昇腾AI设备</p><p>支持代码开发和编译，同时可以运行应用程序或进行训练脚本的迁移、开发&amp;调试</p></li></ul><h3 id="CANN相关安装包解读">CANN相关安装包解读</h3><p><code>Ascend-cann-toolkit_8.0.RC2.alpha002_linux_aarch64.run</code>其中，<code>Ascend</code>和<code>cann</code>是固定前缀，<code>toolkit</code>代表套件软件包，很多在特定场景下的工具包有单独的命名，如<code>Ascend-cann-nnrt_8.0.RC2.alpha002_linux_aarch64.run</code>，<code>nnrt</code>代表推理引擎，其他<code>nnae</code>、<code>kernels</code>代表深度学习引擎软件包和算子二进制安装包。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Host与Device&quot;&gt;Host与Device&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Host指与Device相连的X86服务器、ARM服务器，会利用Device提供的NN（Neural Network）计算能力完成任务&lt;/li&gt;
&lt;li&gt;Device模块指安装了昇腾AI</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Personal-Keyboard-Layout-Optimization.md</title>
    <link href="https://itachicheng.github.io/Personal-Keyboard-Layout-Optimization/"/>
    <id>https://itachicheng.github.io/Personal-Keyboard-Layout-Optimization/</id>
    <published>2025-03-23T07:46:19.000Z</published>
    <updated>2025-03-23T09:09:09.635Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Karabiner-Elements-Config-for-Mac">Karabiner-Elements Config for Mac</h2><p><code>caps_lock</code> can trade off the press of left small finger with right small finger.</p><p>Simple Modifications: <code>caps_lock</code> to <code>left_control</code></p><p>Complex Modifications: Add your own rule</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;caps+ikuo to arrow keys/caps+h caps/semicolon to home/end&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;manipulators&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;n&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;left_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;shift&quot;</span>, <span class="string">&quot;left_option&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;period&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;right_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;shift&quot;</span>, <span class="string">&quot;left_option&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;comma&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;right_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;shift&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;m&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;left_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;shift&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;p&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;right_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;left_option&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;y&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;left_arrow&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;left_option&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;j&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;delete_or_backspace&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;l&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;delete_forward&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;u&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;left_arrow&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;semicolon&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;e&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;left_control&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;h&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;a&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span>: [<span class="string">&quot;left_control&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;o&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;right_arrow&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;i&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;up_arrow&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;from&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;k&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modifiers&quot;</span>: &#123; <span class="attr">&quot;mandatory&quot;</span>: [<span class="string">&quot;control&quot;</span>] &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;to&quot;</span>: [&#123; <span class="attr">&quot;key_code&quot;</span>: <span class="string">&quot;down_arrow&quot;</span> &#125;],</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;basic&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="AutoHotKey-for-Windows">AutoHotKey for Windows</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Karabiner-Elements-Config-for-Mac&quot;&gt;Karabiner-Elements Config for Mac&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;caps_lock&lt;/code&gt; can trade off the press of left </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Jupyter-Config</title>
    <link href="https://itachicheng.github.io/Jupyter-Config/"/>
    <id>https://itachicheng.github.io/Jupyter-Config/</id>
    <published>2025-02-11T02:42:55.000Z</published>
    <updated>2025-05-30T10:56:51.120Z</updated>
    
    <content type="html"><![CDATA[<p>jupyter notebook --generate-config<br>vim /root/.jupyter//jupyter_notebook_config.py<br>nohup jupyter notebook --allow-root &amp;</p><p>c.ServerApp.ip = ‘<em><strong>.</strong>.</em><em>.</em>**’<br>c.ServerApp.notebook_dir = ‘/home/ccc/’<br>c.ServerApp.password_required = True<br>c.ServerApp.port = 7003</p><p>wget <a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh">https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</a><br>sh Miniconda3-latest-Linux-x86_64.sh<br>conda init</p><p>conda create -n torch python=3.10<br>pip install numpy torch pandas jupyter</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;jupyter notebook --generate-config&lt;br&gt;
vim /root/.jupyter//jupyter_notebook_config.py&lt;br&gt;
nohup jupyter notebook --allow-root &amp;amp;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Reinforcement-Learning</title>
    <link href="https://itachicheng.github.io/Reinforcement-Learning/"/>
    <id>https://itachicheng.github.io/Reinforcement-Learning/</id>
    <published>2025-01-29T03:54:26.000Z</published>
    <updated>2025-08-04T06:37:39.026Z</updated>
    
    <content type="html"><![CDATA[<p>出于对股票市场自动化交易的兴趣，在自身交易决策精力有限的情况下，希望通过强化学习来节省投入时间，因而，我开始阅读Maxim Lapan的《Deep Reinforcement Learning Hands-on》。某种角度而言，强化学习比有监督学习所站的维度更高。“Even simple Machine Learning (ML) problems have a hidden time dimension, which is frequently overlooked, but it might become an issue in a production system.”，恰好我需要关注这样的时间维度，因为市场的投资瞬息万变，一如湍流在当前人类常识维度中难以理解。如果不借助更高维度的思维模型，有限的精力是无法与之匹配的。</p><ul><li>“Theoretical foundations of RL: the Markov decision processes”</li><li>&quot;RL is the third camp and lays somewhere in between full supervision and a complete lack of predefined labels. &quot;</li></ul><p>强化学习是在回答诸如“how”的问题，有监督学习是在回答诸如“what”的问题。其中的两个实体，一个是智能体（Agent），另一个是环境（Environment）。智能体得知的是当前的状态（State）以及上一步获得的奖励（Reward），并根据这两个信息在环境中采取动作（Action）。</p><p>在强化学习中需要解决一个问题是如何训练一个智能体，使得智能体能够在合适的状态下产生合适的动作，使后续的奖励总和最大。我们称智能体根据环境状态产生动作的方法为策略（Policy）。</p><p>强化学习的分类：</p><ul><li><p>Policy Optimization：</p><p>深度学习模型描述策略本身</p></li><li><p>Q-Learning:</p><p>在当前状态下未来能够获得的奖励</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;出于对股票市场自动化交易的兴趣，在自身交易决策精力有限的情况下，希望通过强化学习来节省投入时间，因而，我开始阅读Maxim Lapan的《Deep Reinforcement Learning Hands-on》。某种角度而言，强化学习比有监督学习所站的维度更高。“Even</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>内存分配复用</title>
    <link href="https://itachicheng.github.io/Memory-Reuse/"/>
    <id>https://itachicheng.github.io/Memory-Reuse/</id>
    <published>2025-01-14T03:12:59.000Z</published>
    <updated>2025-05-30T10:56:51.121Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>JAX</title>
    <link href="https://itachicheng.github.io/JAX/"/>
    <id>https://itachicheng.github.io/JAX/</id>
    <published>2025-01-11T09:47:16.000Z</published>
    <updated>2025-01-29T03:50:16.115Z</updated>
    
    <content type="html"><![CDATA[<h3 id="JAX-Background">JAX Background</h3><ul><li>High Performance Array Computing</li><li>NumPy on steriods</li><li>Compile and Parallelize code, no matter whether it is deep learning code or, say, ocean simulation weather forecasting</li></ul><h3 id="JAX-Highlight">JAX Highlight</h3><ul><li>A new approach to self-supervised learning called BYOL (Bootstrap Your Own Latent; <a href="https://arxiv.org/abs/2006.07733">https://arxiv.org/abs/2006.07733</a>)</li><li>A general transformer-based architecture for structured inputs and outputs called Perceiver IO (<a href="https://mng.bz/OZ02">https://mng.bz/OZ02</a>)</li><li>Research on large language models (LLMs), with the 280-billion-parameters Gopher model (<a href="https://mng.bz/Y7Be">https://mng.bz/Y7Be</a>) and the 70-billion-parameters Chinchilla (<a href="https://mng.bz/r1yg">https://mng.bz/r1yg</a>)</li></ul><h3 id="Composable-Function-Transformations-of-JAX">Composable-Function-Transformations of JAX</h3><ul><li><strong>Differentiation:</strong> Gradient-based optimisation is fundamental to ML. JAX natively supports both forward and reverse mode <a href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html">automatic differentiation</a> of arbitrary numerical functions, via function transformations such as grad, hessian, jacfwd and jacrev.</li><li><strong>Vectorisation:</strong> In ML research we often apply a single function to lots of data, e.g. calculating the loss across a batch or <a href="https://arxiv.org/abs/2010.09063">evaluating per-example gradients</a> for differentially private learning. JAX provides automatic vectorisation via the vmap transformation that simplifies this form of programming. For example, researchers don’t need to reason about batching when implementing new algorithms. JAX also supports large scale data parallelism via the related pmap transformation, elegantly distributing data that is too large for the memory of a single accelerator.</li><li><strong>JIT-compilation:</strong> <a href="https://www.tensorflow.org/xla">XLA</a> is used to just-in-time (JIT)-compile and execute JAX programs on GPU and <a href="https://cloud.google.com/tpu">Cloud TPU</a> accelerators. JIT-compilation, together with JAX’s NumPy-consistent API, allows researchers with no previous experience in high-performance computing to easily scale to one or many accelerators.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;JAX-Background&quot;&gt;JAX Background&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;High Performance Array Computing&lt;/li&gt;
&lt;li&gt;NumPy on steriods&lt;/li&gt;
&lt;li&gt;Compile and Parall</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Nvidia-Driver-Cuda-CuDNN-Pytorch</title>
    <link href="https://itachicheng.github.io/Nvidia-Driver-Cuda-CuDNN-Pytorch/"/>
    <id>https://itachicheng.github.io/Nvidia-Driver-Cuda-CuDNN-Pytorch/</id>
    <published>2025-01-09T07:47:43.000Z</published>
    <updated>2025-01-11T09:04:07.868Z</updated>
    
    <content type="html"><![CDATA[<h3 id="显卡类型">显卡类型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################ Tesla A100  ##############</span></span></span><br></pre></td></tr></table></figure><h3 id="kernel-headers-and-kernel-devel">kernel-headers and kernel-devel</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dnf install kernel-headers</span><br><span class="line">dnf install kernel-devel</span><br><span class="line">dnf distro-sync</span><br></pre></td></tr></table></figure><h3 id="运行驱动包">运行驱动包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 加上kernel-source-path可能无需重启</span></span></span><br><span class="line">./NVIDIA_Linux-xxxxxxxxx.run --kernel-source-path /usr/src/kernels/6.10****</span><br></pre></td></tr></table></figure><h3 id="nvidia-smi-Time"><code>nvidia-smi</code> Time</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line">+++++++++++++++++++</span><br><span class="line">+ Tesla A100-PCIE +</span><br><span class="line">+++++++++++++++++++</span><br></pre></td></tr></table></figure><h3 id="安装CUDA、CUDNN、minconda、pytorch">安装CUDA、CUDNN、minconda、pytorch</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-rhel7-12-1-local-12.1.1_530.30.02-1.x86_64.rpm --no-check-certificate</span><br><span class="line"></span><br><span class="line">wget https://developer.nvidia.com/downloads/compute/cudnn/secure/8.9.7/local_installers/12.x/cudnn-linux-x86_64-8.9.7.29_cuda12-archive.tar.xz --no-check-certificate</span><br><span class="line"></span><br><span class="line">cd cudnn-linux-x86_64-8.9.7.29_cuda12-archive/</span><br><span class="line">cp include/cudnn.h /usr/local/cuda/include/</span><br><span class="line">cp lib/libcudnn* /usr/local/cuda/lib64/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加CUDA_HOME</span></span><br><span class="line"></span><br><span class="line">curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">chmod +x Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">sh Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加conda环境变量</span></span><br><span class="line"></span><br><span class="line">conda create -n torch2.4 python=3.12</span><br><span class="line">conda activate torch2.4</span><br><span class="line">pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://downloads.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure><h3 id="磁盘挂载">磁盘挂载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdc</span><br><span class="line"></span><br><span class="line">mkfs.ext4 /dev/sdc1</span><br><span class="line">mkfs.ext4 /dev/sdc2</span><br><span class="line"></span><br><span class="line">mkdir -p /data1 /data2</span><br><span class="line">mount /dev/sdc1 /data1</span><br><span class="line">mount /dev/sdc2 /data2</span><br><span class="line"></span><br><span class="line">vim /etc/fstab</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加UUID</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;显卡类型&quot;&gt;显卡类型&lt;/h3&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Self-Attention-for-Memory-Efficiency</title>
    <link href="https://itachicheng.github.io/Self-Attention-for-Memory-Efficiency/"/>
    <id>https://itachicheng.github.io/Self-Attention-for-Memory-Efficiency/</id>
    <published>2024-09-21T07:54:11.000Z</published>
    <updated>2025-01-11T09:04:07.869Z</updated>
    
    <content type="html"><![CDATA[<p>传统Attention的计算方式可以用以下方式简单表达：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><mi>d</mi><mi>o</mi><mi>t</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mspace width="2.155em"/><msubsup><mi>s</mi><mi>i</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>s</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>s</mi><mi>j</mi></msub></msup></mrow></mfrac><mo separator="true">,</mo><mspace width="2.155em"/><mi>a</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mrow><msub><mi>v</mi><mi>i</mi></msub><msubsup><mi>s</mi><mi>i</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">s_i = dot(q, k_i),\hspace{5ex} s_i^{&#x27;} = \frac{e^{s_i}}{\sum_{j}{e^{s_j}}},\hspace{5ex}attention(q, k, v) = \sum_{i}{v_{i}s_i^{&#x27;}}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2425em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:2.155em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9925em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:2.155em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9925em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">q\in{R^d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>是一个d维的向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi>e</mi><mi>y</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">keys</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">eys</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">values</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">es</span></span></span></span>分别是d维向量组成的序列，例如，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">k_1,...,k_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">v_1,...,v_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,序列长度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>，可以对Attention的计算进行可视化：</p><p><img src="./Self-Attention-for-Memory-Efficiency.assets/image-20240922234546414.png" alt="image-20240922234546414"><br><img src="./Self-Attention-for-Memory-Efficiency.assets/image-20240922234612296.png" alt="image-20240922234612296"></p><p>在求解attention（Q， K，V）的整个过程中，如果将d视为常数，那么空间复杂度为O（n）。实际上，n这个维度可以看成时间延展，通过时间换空间，可以仅在（1，d）的size上做累加计算得到atten。而对应的<strong>Self-Attention</strong>，尽管query另一维度也可以拓展到n维，但实现的空间复杂度也不需要<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。这也是Flash-Attention的基本思想。</p><p><img src="./Self-Attention-for-Memory-Efficiency.assets/image-20240923001802231.png" alt="image-20240923001802231"></p><p><img src="./Self-Attention-for-Memory-Efficiency.assets/image-20240923001916003.png" alt="image-20240923001916003"></p><p>合理利用HBM以及SRAM的存储可以使attention变得内存高效，其中在K,V维度的切分，形成外层循环，Q维度的切分，形成内层循环。</p><h4 id="Evoformer-Attention中的类似优化">Evoformer_Attention中的类似优化</h4><p>按大小为B的块逐步计算输出， 只需要将最终结果除以softmax中所有系数的总和，伪代码描述如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s_prime = torch.zeros([num_queries, B])</span><br><span class="line">O = torch.zeros([num_queries, head_size_v])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, K.shape[<span class="number">0</span>], B):</span><br><span class="line">    si = exp((Q . K[i * B:(i+<span class="number">1</span>) * B].t) * scale)</span><br><span class="line">    sum_coefs += attn_unscaled.<span class="built_in">sum</span>(-<span class="number">1</span>)</span><br><span class="line">    O += si . V[i * B:(i+<span class="number">1</span>) * B]</span><br><span class="line">O = O / s_prime</span><br></pre></td></tr></table></figure><p>出于数值稳定性的原因， 我们还在进行指数运算之前减去迄今为止的最大值（<code>mi</code>）。 当我们遇到新的键时，用于计算O的最大值（<code>m_prime</code>） 可能与当前最大值不同，所以我们在累积之前更新O。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">O = O * exp(m_prime - mi)</span><br><span class="line">m_prime = mi</span><br></pre></td></tr></table></figure><p>实现细节：</p><ul><li><code>si</code> 在两次连续的GEMM（通用矩阵乘法）之间存储在共享内存中</li><li>如果我们可以（<code>head_size_v &lt;= 128</code>），我们直接在寄存器中存储并累积输出 否则，我们将其存储在全局内存中（较慢）</li><li>块在批处理维度、头数和查询序列大小上并行化</li><li>对bias也进行内层循环中的即时广播</li></ul><h4 id="核心代码标识">核心代码标识</h4><h5 id="kernel-forward-h">kernel_forward.h</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> CUTLASS_DEVICE <span class="title">attention_kernel</span><span class="params">(Params&amp; p)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// In this block, we will only ever:</span></span><br><span class="line">        <span class="comment">// - read query[query_start:query_end, :]</span></span><br><span class="line">        <span class="comment">// - write to output[query_start:query_end, :]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 对中间变量应用共享内存</span></span><br><span class="line">        <span class="keyword">extern</span> __shared__ <span class="keyword">char</span> smem_buffer[];</span><br><span class="line">        SharedStorage&amp; shared_storage = *((SharedStorage*)smem_buffer);</span><br><span class="line">        <span class="keyword">auto</span>&amp; m_prime = shared_storage.m_prime;</span><br><span class="line">        <span class="keyword">auto</span>&amp; s_prime = shared_storage.s_prime;</span><br><span class="line">        <span class="keyword">auto</span>&amp; mi = shared_storage.mi;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">uint32_t</span> query_start = blockIdx.x * kQueriesPerBlock;</span><br><span class="line">...</span><br><span class="line">        <span class="comment">// 对key、value进行切分</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int32_t</span> iter_key_start = <span class="number">0</span>; iter_key_start &lt; p.num_keys;</span><br><span class="line">             iter_key_start += kKeysPerBlock) &#123;</span><br><span class="line">            </span><br><span class="line">...</span><br><span class="line">                </span><br><span class="line">            <span class="comment">// 如果需要对bias计算，则进行即时广播</span></span><br><span class="line">            <span class="keyword">if</span> (kSupportsBias) &#123;</span><br><span class="line">...</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">         ...</span><br><span class="line">            <span class="comment">// query的block切分</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> blockN = <span class="number">0</span>; blockN &lt; nBlockN; ++blockN) &#123;</span><br><span class="line">                ...</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            __syncthreads();  <span class="comment">// we modify `m_prime` after</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7. Calculate logsumexp</span></span><br><span class="line">        <span class="comment">// To make the backward easier, we pad logsumexp with `inf`</span></span><br><span class="line">        <span class="comment">// this avoids a few bound checks, and is not more expensive during fwd</span></span><br><span class="line">        <span class="built_in"><span class="keyword">static_assert</span></span>(kQueriesPerBlock &lt; kNumWarpsPerBlock * kWarpSize, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (p.logsumexp_ptr &amp;&amp; <span class="built_in">thread_id</span>() &lt; kQueriesPerBlock) &#123;</span><br><span class="line">            <span class="keyword">auto</span> lse_dim = <span class="built_in">ceil_div</span>((<span class="keyword">int32_t</span>)p.num_queries, kAlignLSE) * kAlignLSE;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">thread_id</span>() &lt; p.num_queries) &#123;</span><br><span class="line">                p.logsumexp_ptr[<span class="built_in">thread_id</span>()] =</span><br><span class="line">                    <span class="built_in">accum_t</span>(mi[<span class="built_in">thread_id</span>()]) + cutlass::<span class="built_in">fast_log</span>(<span class="built_in">accum_t</span>(s_prime[<span class="built_in">thread_id</span>()]));</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">thread_id</span>() &lt; lse_dim) &#123;</span><br><span class="line">                p.logsumexp_ptr[<span class="built_in">thread_id</span>()] =</span><br><span class="line">                    cutlass::platform::numeric_limits&lt;<span class="keyword">accum_t</span>&gt;::<span class="built_in">infinity</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;传统Attention的计算方式可以用以下方式简单表达：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>CUTLASS-With-Windows</title>
    <link href="https://itachicheng.github.io/CUTLASS-With-Windows/"/>
    <id>https://itachicheng.github.io/CUTLASS-With-Windows/</id>
    <published>2024-09-14T15:11:57.000Z</published>
    <updated>2025-01-11T09:04:07.867Z</updated>
    
    <content type="html"><![CDATA[<h3 id="查看GPU设备的计算能力">查看GPU设备的计算能力</h3><p><code>C:\Program Files\NVIDIA GPU Computing\Toolkit\CUDA\v12.6\extras\demo_suite\deviceQuery.exe</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">deviceQuery.exe Starting...</span><br><span class="line"></span><br><span class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</span><br><span class="line"></span><br><span class="line">Detected 1 CUDA Capable device(s)</span><br><span class="line"></span><br><span class="line">Device 0: &quot;NVIDIA GeForce RTX 2060&quot;</span><br><span class="line">  CUDA Driver Version / Runtime Version          12.6 / 12.6</span><br><span class="line">  CUDA Capability Major/Minor version number:    7.5</span><br><span class="line">  Total amount of global memory:                 6144 MBytes (6442123264 bytes)</span><br><span class="line">  (30) Multiprocessors, ( 64) CUDA Cores/MP:     1920 CUDA Cores</span><br><span class="line">  GPU Max Clock rate:                            1680 MHz (1.68 GHz)</span><br><span class="line">  Memory Clock rate:                             7001 Mhz</span><br><span class="line">  Memory Bus Width:                              192-bit</span><br><span class="line">  L2 Cache Size:                                 3145728 bytes</span><br><span class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</span><br><span class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</span><br><span class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</span><br><span class="line">  Total amount of constant memory:               zu bytes</span><br><span class="line">  Total amount of shared memory per block:       zu bytes</span><br><span class="line">  Total number of registers available per block: 65536</span><br><span class="line">  Warp size:                                     32</span><br><span class="line">  Maximum number of threads per multiprocessor:  1024</span><br><span class="line">  Maximum number of threads per block:           1024</span><br><span class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br><span class="line">  Maximum memory pitch:                          zu bytes</span><br><span class="line">  Texture alignment:                             zu bytes</span><br><span class="line">  Concurrent copy and kernel execution:          Yes with 6 copy engine(s)</span><br><span class="line">  Run time limit on kernels:                     Yes</span><br><span class="line">  Integrated GPU sharing Host Memory:            No</span><br><span class="line">  Support host page-locked memory mapping:       Yes</span><br><span class="line">  Alignment requirement for Surfaces:            Yes</span><br><span class="line">  Device has ECC support:                        Disabled</span><br><span class="line">  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)</span><br><span class="line">  Device supports Unified Addressing (UVA):      Yes</span><br><span class="line">  Device supports Compute Preemption:            Yes</span><br><span class="line">  Supports Cooperative Kernel Launch:            Yes</span><br><span class="line">  Supports MultiDevice Co-op Kernel Launch:      No</span><br><span class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0</span><br><span class="line">  Compute Mode:</span><br><span class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</span><br><span class="line"></span><br><span class="line">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.6, CUDA Runtime Version = 12.6, NumDevs = 1, Device0 = NVIDIA GeForce RTX 2060</span><br><span class="line">Result = PASS</span><br></pre></td></tr></table></figure><h3 id="下载CUTLASS压缩包">下载CUTLASS压缩包</h3><p>地址：<a href="https://github.com/NVIDIA/cutlass/archive/refs/tags/v3.5.0.zip">https://github.com/NVIDIA/cutlass/archive/refs/tags/v3.5.0.zip</a></p><p><img src="./CUTLASS-With-Windows.assets/image-20240914233132449.png" alt="image-20240914233132449"></p><h3 id="解压并新建build文件夹">解压并新建build文件夹</h3><p>在build文件夹中，可以通过Cmake生成Visual Studio项目管理文件，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake .. -DCUTLASS_NVCC_ARCHS=75(对应上述CUDA Capability7.5)</span><br></pre></td></tr></table></figure><p><img src="./CUTLASS-With-Windows.assets/image-20240914233811190.png" alt="image-20240914233811190"></p><p>通过Visual Studio打开build/CUTLASS.sln，我们可以得到对examples所有案例的管理。<code>本地Windows调试器</code>-&gt;<code>配置启动项目</code>，选择<code>当前选定内容</code>，之后可以对选中的案例进行单独生成执行。</p><p><img src="./CUTLASS-With-Windows.assets/image-20240914234246948.png" alt="image-20240914234246948"></p><p>运行结果如下所示：</p><p><img src="./CUTLASS-With-Windows.assets/image-20240914234150247.png" alt="image-20240914234150247"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;查看GPU设备的计算能力&quot;&gt;查看GPU设备的计算能力&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;C:\Program Files\NVIDIA GPU Computing\Toolkit\CUDA\v12.6\extras\demo_suite\deviceQuery.exe&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Aliyun_Server</title>
    <link href="https://itachicheng.github.io/Aliyun-Server/"/>
    <id>https://itachicheng.github.io/Aliyun-Server/</id>
    <published>2024-09-11T03:23:07.000Z</published>
    <updated>2025-01-11T09:04:07.866Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/fatedier/frp">frp</a> 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议，且支持 P2P 通信。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。</p><h3 id="云服务器侧frp配置">云服务器侧frp配置</h3><ul><li><h4 id="查看服务器防火墙状态">查看服务器防火墙状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Ubuntu</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Centos</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 开放部分端口</span></span><br></pre></td></tr></table></figure></li><li><p>阿里云安全组设置开启外部访问端口</p></li><li><p>下载对应frp版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/fatedier/frp/releases/download/v0.49.0/frp_0.49.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>解压并修改配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf frp_0.49.0_linux_amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cd frp_0.49.0_linux_amd64/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 服务器端设置frps.ini</span></span></span><br><span class="line">vim frps.ini</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 设置选项，保存退出</span></span></span><br><span class="line">[common]</span><br><span class="line">bind_port = xxxx</span><br><span class="line">dashboard_port = ####</span><br><span class="line">dashboard_user = ####</span><br><span class="line">dashboard_pwd = ####</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 后台运行</span></span></span><br><span class="line">nohup ./frps -c ./frps.ini &amp;</span><br></pre></td></tr></table></figure></li></ul><h3 id="本地客户端frp配置">本地客户端frp配置</h3><ul><li><p>下载对应frp版本并解压</p><p>浏览器下载：<a href="https://github.com/fatedier/frp/releases/download/v0.49.0/frp_0.49.0_windows_amd64.zip">https://github.com/fatedier/frp/releases/download/v0.49.0/frp_0.49.0_windows_amd64.zip</a></p></li><li><p>新建frpc.bat</p><p>路径：C:\ProgramData\Microsoft\Windows\Start Menu\Programs\StartUp\frpc.bat</p></li><li><p>编写自启动文件frpc.bat</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmd /c D:\Tools\FRP\frp_0.49.0_windows_amd64\frp_0.49.0_windows_amd64\frpc.exe -c D:\Tools\FRP\frp_0.49.0_windows_amd64\frp_0.49.0_windows_amd64\frpc.ini</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>添加配置选项</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[common]</span><br><span class="line">server<span class="emphasis">_addr = 云服务器上的公网ip</span></span><br><span class="line"><span class="emphasis">server_</span>port = xxxx （同上bind<span class="emphasis">_port）</span></span><br><span class="line"><span class="emphasis">[RDP]</span></span><br><span class="line"><span class="emphasis">type = tcp</span></span><br><span class="line"><span class="emphasis">local_</span>ip = 127.0.0.1</span><br><span class="line">local<span class="emphasis">_port = #### （本地开放端口）</span></span><br><span class="line"><span class="emphasis">remote_</span>port = #### （外部可访问端口）</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><p>通过以上配置可以用于windows远程桌面连接，透过windows本身在的局域网。</p><h3 id="Jupyter-Notebook服务器挂载">Jupyter Notebook服务器挂载</h3><ul><li><h4 id="基础Conda环境安装">基础Conda环境安装</h4><p>miniconda下载，并通过sh执行，创建并初始化Conda环境。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base)computer_name:path#  pip install jupyter</span><br></pre></td></tr></table></figure></li><li><h4 id="Jupyter-Notebook配置文件并修改">Jupyter Notebook配置文件并修改</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 修改配置文件</span></span></span><br><span class="line">vim /root/.jupyter/jupyter_notebook_config.py</span><br><span class="line"></span><br><span class="line">c.#####.notebook_dir = &quot;/path/to/file&quot;</span><br><span class="line">c.#####.password_required = True</span><br><span class="line">c.#####.port = PPPP（需要在安全组和防火墙中开放端口）</span><br><span class="line">c.#####.ip = xxx.xxx.xxx.xxx（阿里云服务器中的私有ip，公有ip用于外部访问，私有ip用于拉起服务）</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><h4 id="开启Jupyter-Notebook服务">开启Jupyter Notebook服务</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置jupyter notebook密码</span></span></span><br><span class="line">jupyter notebook password</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 输入密码</span></span></span><br><span class="line">Enter password: XXXXXX</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 开启服务</span></span></span><br><span class="line">nohup jupyter notebook --allow-root &amp;</span><br></pre></td></tr></table></figure></li><li><h4 id="外部访问登陆界面">外部访问登陆界面</h4><p>浏览器输入 ：<a href="http://xn--ip-xz4cu9bf8io83arv1b">http://服务器公网ip</a>:PPPP</p><p><img src="./Aliyun-Server.assets/jupyter_notebook_login.png" alt="jupyter notebook login"></p><p>密码输入（同<code>Enter password</code>）。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://github.com/fatedier/frp&quot;&gt;frp&lt;/a&gt; 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议，且支持 P2P 通信。可以将内网服务以安全、便捷的方式通过具有公网 IP </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>DeepSpeed</title>
    <link href="https://itachicheng.github.io/DeepSpeed/"/>
    <id>https://itachicheng.github.io/DeepSpeed/</id>
    <published>2024-07-21T12:01:50.000Z</published>
    <updated>2025-08-04T06:37:39.021Z</updated>
    
    <content type="html"><![CDATA[<p>DeepSpeed</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;DeepSpeed&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>DeePMD-kit</title>
    <link href="https://itachicheng.github.io/DeePMD-kit/"/>
    <id>https://itachicheng.github.io/DeePMD-kit/</id>
    <published>2024-06-19T02:39:35.000Z</published>
    <updated>2024-07-10T16:04:18.368Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DeePMD-kit">DeePMD-kit</h3><ul><li>给定第一性原理数据，训练深度势能模型<ul><li>VASP</li><li>CP2K</li><li>QE</li><li>ABACUS</li><li>SIESTA</li><li>GAUSSIAN</li></ul></li><li>将深度势能模型与常用分子动力学引擎结合<ul><li>LAMMPS</li><li>GROMACS</li><li>OPENMM</li></ul></li></ul><h3 id="DP-GEN">DP-GEN</h3><ul><li>利用同步学习框架，产生数据集<ul><li>探索</li><li>标注</li><li>训练</li></ul></li></ul><h3 id="dpdata">dpdata</h3><ul><li>多种软件间坐标文件格式转化</li></ul><h3 id="实践-参考：快速开始-DeePMD-kit｜训练甲烷深度势能分子动力学模型">实践(参考：<a href="https://bohrium.dp.tech/">快速开始 DeePMD-kit｜训练甲烷深度势能分子动力学模型</a>)</h3><h4 id="1-数据准备">1 数据准备</h4><p>DeePMD-kit 的训练数据来源于第一性原理计算数据，包含原子类型、模拟晶格、原子坐标、原子力、系统能量和维里量。</p><div align="left" style="margin:1.5rem"><img src="workflow.jpg" alt="image-20230116161737203" style="zoom: 25%;"></div><p>在 <em>00.data</em> 文件夹下仅有 <em>abacus_md</em> 文件夹，<em>abacus_md</em> 文件夹是通过使用 ABACUS 进行从头算分子动力学 (<em>ab initio</em> Molecular Dynamics, AIMD) 获得的。</p><p>DeePMD-kit 采用压缩数据格式。所有训练数据应首先转换为此格式，然后可以在 DeePMD-kit 中使用。该数据格式在 DeePMD-kit 手册中有详细解释，可以在<a href="http://www.github.com/deepmodeling/deepmd-kit">DeePMD-kit Github</a>中找到。</p><p>我们提供了一个方便的工具 <strong>dpdata</strong>，可以将由 VASP、CP2K、Gaussian、Quantum-Espresso、ABACUS 和 LAMMPS 产生的数据转换为 DeePMD-kit 的压缩格式。</p><p>具有计算数据信息的分子系统的快照(snapshot)称为帧。数据系统包括许多共享相同原子数和原子类型的帧。</p><p>例如，分子动力学轨迹可以转换为数据系统，其中每个时间步长对应于系统中的一帧。</p><p>接下来，我们使用 dpdata 工具将 <em>abacus_md</em> 中的数据随机分成训练和验证数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dpdata </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入 ABACUS/MD 格式的数据</span></span><br><span class="line">data = dpdata.LabeledSystem(<span class="string">&#x27;DeePMD-kit_Tutorial/00.data/abacus_md&#x27;</span>, fmt = <span class="string">&#x27;abacus/md&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# 数据包含%d帧&#x27;</span> % <span class="built_in">len</span>(data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机选择40个索引作为验证集数据</span></span><br><span class="line">index_validation = np.random.choice(<span class="number">201</span>,size=<span class="number">40</span>,replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他索引作为训练集数据</span></span><br><span class="line">index_training = <span class="built_in">list</span>(<span class="built_in">set</span>(<span class="built_in">range</span>(<span class="number">201</span>))-<span class="built_in">set</span>(index_validation))</span><br><span class="line">data_training = data.sub_system(index_training)</span><br><span class="line">data_validation = data.sub_system(index_validation)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有训练数据放入文件夹&quot;training_data&quot;中</span></span><br><span class="line">data_training.to_deepmd_npy(<span class="string">&#x27;DeePMD-kit_Tutorial/00.data/training_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有验证数据放入文件夹&quot;validation_data&quot;中</span></span><br><span class="line">data_validation.to_deepmd_npy(<span class="string">&#x27;DeePMD-kit_Tutorial/00.data/validation_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# 训练数据包含%d帧&#x27;</span> % <span class="built_in">len</span>(data_training)) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# 验证数据包含%d帧&#x27;</span> % <span class="built_in">len</span>(data_validation))</span><br></pre></td></tr></table></figure><p>可以看到，161个帧被选为训练数据，其他40个帧是验证数据。</p><p>让我们再查看一下 00.data 文件夹，其中产生了新的文件，分别是 DeePMD-kit 深度势能训练所需的训练集和验证集。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! tree DeePMD-kit_Tutorial/00.data/ -L 1</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DeePMD-kit_Tutorial/00.data/</span><br><span class="line">├── abacus_md</span><br><span class="line">├── training_data</span><br><span class="line">└── validation_data</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! tree DeePMD-kit_Tutorial/00.data/training_data -L 1</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DeePMD-kit_Tutorial/00.data/training_data</span><br><span class="line">├── set.000</span><br><span class="line">├── type.raw</span><br><span class="line">└── type_map.raw</span><br></pre></td></tr></table></figure><p>这些文件的作用如下：</p><ol><li><code>set.000</code>：是一个目录，包含压缩格式的数据（NumPy压缩数组）。</li><li><code>type.raw</code>：是一个文件，包含原子的类型（以整数表示）。</li><li><code>type_map.raw</code>：是一个文件，包含原子的类型名称。</li></ol><p>让我们来看一下这些文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">! cat DeePMD-kit_Tutorial/00.data/training_data/type.raw </span><br><span class="line">0</span><br><span class="line">0</span><br><span class="line">0</span><br><span class="line">0</span><br><span class="line">1</span><br></pre></td></tr></table></figure><p>这告诉我们这个例子中有5个原子，其中4个原子由类型&quot;0&quot;表示，1个原子由类型&quot;1&quot;表示。有时需要将整数类型映射到原子名称。映射可以通过文件<code>type_map.raw</code>给出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">! cat DeePMD-kit_Tutorial/<span class="number">00.</span>data/training_data/type_map.raw</span><br><span class="line">H</span><br><span class="line">C</span><br></pre></td></tr></table></figure><p>这告诉我们类型“0”被命名为“H”，类型“1”被命名为“C”。</p><h4 id="2-准备输入脚本">2 准备输入脚本</h4><p>训练数据准备完成后，接下来就可以进行训练。DeePMD-kit 需要一个<code>json</code>格式的文件来指定训练参数。该文件称为 DeePMD-kit 的输入脚本，让我们进入训练目录看一下该输入脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! cd DeePMD-kit_Tutorial/01.train/ &amp;&amp; cat input.json</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>: <span class="string">&quot; model parameters&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;model&quot;</span>: &#123;</span><br><span class="line"><span class="attr">&quot;type_map&quot;</span>:[<span class="string">&quot;H&quot;</span>, <span class="string">&quot;C&quot;</span>],</span><br><span class="line"><span class="attr">&quot;descriptor&quot;</span> :&#123;</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>:<span class="string">&quot;se_e2_a&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;sel&quot;</span>:<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;rcut_smth&quot;</span>:<span class="number">0.50</span>,</span><br><span class="line">    <span class="attr">&quot;rcut&quot;</span>:<span class="number">6.00</span>,</span><br><span class="line">    <span class="attr">&quot;neuron&quot;</span>:[<span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>],</span><br><span class="line">    <span class="attr">&quot;resnet_dt&quot;</span>:<span class="literal">false</span>,</span><br><span class="line">    <span class="attr">&quot;axis_neuron&quot;</span>:<span class="number">16</span>,</span><br><span class="line">    <span class="attr">&quot;seed&quot;</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot; that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">&quot;fitting_net&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;neuron&quot;</span>:[<span class="number">240</span>, <span class="number">240</span>, <span class="number">240</span>],</span><br><span class="line">    <span class="attr">&quot;resnet_dt&quot;</span>:<span class="literal">true</span>,</span><br><span class="line">    <span class="attr">&quot;seed&quot;</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot; that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot; that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;learning_rate&quot;</span> :&#123;</span><br><span class="line"><span class="attr">&quot;type&quot;</span>:<span class="string">&quot;exp&quot;</span>,</span><br><span class="line"><span class="attr">&quot;decay_steps&quot;</span>:<span class="number">50</span>,</span><br><span class="line"><span class="attr">&quot;start_lr&quot;</span>:<span class="number">0.001</span>,</span><br><span class="line"><span class="attr">&quot;stop_lr&quot;</span>:<span class="number">3.51e-8</span>,</span><br><span class="line"><span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;loss&quot;</span> :&#123;</span><br><span class="line"><span class="attr">&quot;type&quot;</span>:<span class="string">&quot;ener&quot;</span>,</span><br><span class="line"><span class="attr">&quot;start_pref_e&quot;</span>:<span class="number">0.02</span>,</span><br><span class="line"><span class="attr">&quot;limit_pref_e&quot;</span>:<span class="number">1</span>,</span><br><span class="line"><span class="attr">&quot;start_pref_f&quot;</span>:<span class="number">1000</span>,</span><br><span class="line"><span class="attr">&quot;limit_pref_f&quot;</span>:<span class="number">1</span>,</span><br><span class="line"><span class="attr">&quot;start_pref_v&quot;</span>:<span class="number">0</span>,</span><br><span class="line"><span class="attr">&quot;limit_pref_v&quot;</span>:<span class="number">0</span>,</span><br><span class="line"><span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot; that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;training&quot;</span> : &#123;</span><br><span class="line"><span class="attr">&quot;training_data&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;systems&quot;</span>:     [<span class="string">&quot;../00.data/training_data&quot;</span>],</span><br><span class="line">    <span class="attr">&quot;batch_size&quot;</span>:  <span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:   <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">&quot;validation_data&quot;</span>:&#123;</span><br><span class="line">    <span class="attr">&quot;systems&quot;</span>:   [<span class="string">&quot;../00.data/validation_data&quot;</span>],</span><br><span class="line">    <span class="attr">&quot;batch_size&quot;</span>:  <span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;numb_btch&quot;</span>:   <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:   <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">&quot;numb_steps&quot;</span>:<span class="number">10000</span>,</span><br><span class="line"><span class="attr">&quot;seed&quot;</span>:<span class="number">10</span>,</span><br><span class="line"><span class="attr">&quot;disp_file&quot;</span>:<span class="string">&quot;lcurve.out&quot;</span>,</span><br><span class="line"><span class="attr">&quot;disp_freq&quot;</span>:<span class="number">200</span>,</span><br><span class="line"><span class="attr">&quot;save_freq&quot;</span>:<span class="number">1000</span>,</span><br><span class="line"><span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,    </span><br><span class="line"></span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:<span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在模型部分，指定了嵌入和拟合网络的参数。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;model&quot;</span>:&#123;</span><br><span class="line">    <span class="attr">&quot;type_map&quot;</span>:    [<span class="string">&quot;H&quot;</span>, <span class="string">&quot;C&quot;</span>],                 </span><br><span class="line">    <span class="attr">&quot;descriptor&quot;</span>:&#123;</span><br><span class="line">        <span class="attr">&quot;type&quot;</span>:            <span class="string">&quot;se_e2_a&quot;</span>,          </span><br><span class="line">        <span class="attr">&quot;rcut&quot;</span>:            <span class="number">6.00</span>,               </span><br><span class="line">        <span class="attr">&quot;rcut_smth&quot;</span>:       <span class="number">0.50</span>,               </span><br><span class="line">        <span class="attr">&quot;sel&quot;</span>:             <span class="string">&quot;auto&quot;</span>,             </span><br><span class="line">        <span class="attr">&quot;neuron&quot;</span>:          [<span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>],       </span><br><span class="line">        <span class="attr">&quot;resnet_dt&quot;</span>:       <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">&quot;axis_neuron&quot;</span>:     <span class="number">16</span>,                  </span><br><span class="line">        <span class="attr">&quot;seed&quot;</span>:            <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;_comment&quot;</span>:        <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="attr">&quot;fitting_net&quot;</span>:&#123;</span><br><span class="line">        <span class="attr">&quot;neuron&quot;</span>:          [<span class="number">240</span>, <span class="number">240</span>, <span class="number">240</span>],    </span><br><span class="line">        <span class="attr">&quot;resnet_dt&quot;</span>:       <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">&quot;seed&quot;</span>:            <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;_comment&quot;</span>:        <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:    <span class="string">&quot;that&#x27;s all&quot;</span>&#x27;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>部分参数的解释如下：</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>type_map</td><td>每种原子的名称</td></tr><tr><td>descriptor &gt; type</td><td>描述类型</td></tr><tr><td>descriptor &gt; rcut</td><td>截断半径</td></tr><tr><td>descriptor &gt; rcut_smth</td><td>平滑开始的位置</td></tr><tr><td>descriptor &gt; sel</td><td>切割半径内第i种原子的最大数目</td></tr><tr><td>descriptor &gt; neuron</td><td>嵌入神经网络的大小</td></tr><tr><td>descriptor &gt; axis_neuron</td><td>G矩阵的子矩阵大小(嵌入矩阵)</td></tr><tr><td>fitting_net &gt; neuron</td><td>拟合神经网络的大小</td></tr></tbody></table><p>使用<code>se_e2_a</code>描述符来训练DP模型。<code>neurons</code>的参数将描述符和拟合网络的大小分别设置为[25, 50, 100]和[240, 240, 240]。本地环境中的组成部分会在从0.5到6 Å的范围内平滑地趋于零。</p><p>以下是指定学习率和损失函数的参数。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;learning_rate&quot;</span> :&#123;</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>:                <span class="string">&quot;exp&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;decay_steps&quot;</span>:         <span class="number">50</span>,</span><br><span class="line">    <span class="attr">&quot;start_lr&quot;</span>:            <span class="number">0.001</span>,    </span><br><span class="line">    <span class="attr">&quot;stop_lr&quot;</span>:             <span class="number">3.51e-8</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:            <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">&quot;loss&quot;</span> :&#123;</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>:                <span class="string">&quot;ener&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;start_pref_e&quot;</span>:        <span class="number">0.02</span>,</span><br><span class="line">    <span class="attr">&quot;limit_pref_e&quot;</span>:        <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;start_pref_f&quot;</span>:        <span class="number">1000</span>,</span><br><span class="line">    <span class="attr">&quot;limit_pref_f&quot;</span>:        <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;start_pref_v&quot;</span>:        <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;limit_pref_v&quot;</span>:        <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;_comment&quot;</span>:            <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>在损失函数中，<code>pref_e</code>从 0.02 逐渐增加到 1，<code>pref_f</code>从 1000 逐渐减小到 1，这意味着力项在开始时占主导地位，而能量和压力项在最后变得重要。这种策略非常有效，并减少了总的训练时间。<code>pref_v</code>设置为 0，表示训练过程中不包括压力数据。起始学习率、终止学习率和衰减步数分别设置为 0.001、3.51e-8 和 50。模型训练 10000 步。</p><p>训练参数如下所示：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;training&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;training_data&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;systems&quot;</span>:            [<span class="string">&quot;../00.data/training_data&quot;</span>],     </span><br><span class="line">        <span class="attr">&quot;batch_size&quot;</span>:         <span class="string">&quot;auto&quot;</span>,                       </span><br><span class="line">        <span class="attr">&quot;_comment&quot;</span>:           <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;validation_data&quot;</span>:&#123;</span><br><span class="line">        <span class="attr">&quot;systems&quot;</span>:            [<span class="string">&quot;../00.data/validation_data/&quot;</span>],</span><br><span class="line">        <span class="attr">&quot;batch_size&quot;</span>:         <span class="string">&quot;auto&quot;</span>,               </span><br><span class="line">        <span class="attr">&quot;numb_btch&quot;</span>:          <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;_comment&quot;</span>:           <span class="string">&quot;that&#x27;s all&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;numb_steps&quot;</span>:             <span class="number">10000</span>,                           </span><br><span class="line">    <span class="attr">&quot;seed&quot;</span>:                   <span class="number">10</span>,</span><br><span class="line">    <span class="attr">&quot;disp_file&quot;</span>:              <span class="string">&quot;lcurve.out&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;disp_freq&quot;</span>:              <span class="number">200</span>,</span><br><span class="line">    <span class="attr">&quot;save_freq&quot;</span>:              <span class="number">10000</span>,</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure><h4 id="3-训练模型">3 训练模型</h4><p>准备好训练脚本后，我们可以通过简单地运行 DeePMD-kit 来开始训练。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="comment">########## Time Warning: 8 mins 48 secs ##########</span></span></span><br><span class="line">! cd DeePMD-kit_Tutorial/01.train/ &amp;&amp; dp train input.json</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">non-resource variables are not supported in the long term</span><br><span class="line">WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.</span><br><span class="line">WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0</span><br><span class="line">WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0</span><br><span class="line">/opt/deepmd-kit-2.2.1/lib/python3.10/importlib/__init__.py:169: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.</span><br><span class="line">  _bootstrap._exec(spec, module)</span><br><span class="line">DEEPMD INFO    Calculate neighbor statistics... (add --skip-neighbor-stat to skip this step)</span><br><span class="line">2023-09-25 18:08:39.837014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#x27;libcuda.so.1&#x27;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64</span><br><span class="line">2023-09-25 18:08:39.837045: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)</span><br><span class="line">OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0,1</span><br><span class="line">OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.</span><br><span class="line">OMP: Info #216: KMP_AFFINITY: cpuid leaf 11 not supported.</span><br><span class="line">OMP: Info #216: KMP_AFFINITY: decoding legacy APIC ids.</span><br><span class="line">OMP: Info #157: KMP_AFFINITY: 2 available OS procs</span><br><span class="line">OMP: Info #158: KMP_AFFINITY: Uniform topology</span><br><span class="line">OMP: Info #287: KMP_AFFINITY: topology layer &quot;LL cache&quot; is equivalent to &quot;socket&quot;.</span><br><span class="line">OMP: Info #192: KMP_AFFINITY: 1 socket x 1 core/socket x 2 threads/core (1 total cores)</span><br><span class="line">OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:</span><br><span class="line">OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 </span><br><span class="line">OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 0 thread 1 </span><br><span class="line">OMP: Info #254: KMP_AFFINITY: pid 99 tid 109 thread 1 bound to OS proc set 1</span><br><span class="line">OMP: Info #254: KMP_AFFINITY: pid 99 tid 111 thread 2 bound to OS proc set 0</span><br><span class="line">OMP: Info #254: KMP_AFFINITY: pid 99 tid 108 thread 3 bound to OS proc set 1</span><br><span class="line">OMP: Info #254: KMP_AFFINITY: pid 99 tid 112 thread 4 bound to OS proc set 0</span><br><span class="line">DEEPMD INFO    training data with min nbor dist: 1.045920568611028</span><br><span class="line">DEEPMD INFO    training data with max nbor size: [4 1]</span><br><span class="line">DEEPMD INFO     _____               _____   __  __  _____           _     _  _   </span><br><span class="line">DEEPMD INFO    |  __ \             |  __ \ |  \/  ||  __ \         | |   (_)| |  </span><br><span class="line">DEEPMD INFO    | |  | |  ___   ___ | |__) || \  / || |  | | ______ | | __ _ | |_ </span><br><span class="line">DEEPMD INFO    | |  | | / _ \ / _ \|  ___/ | |\/| || |  | ||______|| |/ /| || __|</span><br><span class="line">DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   &lt; | || |_ </span><br><span class="line">DEEPMD INFO    |_____/  \___| \___||_|     |_|  |_||_____/         |_|\_\|_| \__|</span><br><span class="line">DEEPMD INFO    Please read and cite:</span><br><span class="line">DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)</span><br><span class="line">DEEPMD INFO    installed to:         /home/conda/feedstock_root/build_artifacts/deepmd-kit_1678943793317/work/_skbuild/linux-x86_64-3.10/cmake-install</span><br><span class="line">DEEPMD INFO    source :              v2.2.1</span><br><span class="line">DEEPMD INFO    source brach:         HEAD</span><br><span class="line">DEEPMD INFO    source commit:        3ac8c4c7</span><br><span class="line">DEEPMD INFO    source commit at:     2023-03-16 12:33:24 +0800</span><br><span class="line">DEEPMD INFO    build float prec:     double</span><br><span class="line">DEEPMD INFO    build variant:        cuda</span><br><span class="line">DEEPMD INFO    build with tf inc:    /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/include;/opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/../../../../include</span><br><span class="line">DEEPMD INFO    build with tf lib:    </span><br><span class="line">DEEPMD INFO    ---Summary of the training---------------------------------------</span><br><span class="line">DEEPMD INFO    running on:           bohrium-14076-1043333</span><br><span class="line">DEEPMD INFO    computing device:     cpu:0</span><br><span class="line">DEEPMD INFO    CUDA_VISIBLE_DEVICES: unset</span><br><span class="line">DEEPMD INFO    Count of visible GPU: 0</span><br><span class="line">DEEPMD INFO    num_intra_threads:    0</span><br><span class="line">DEEPMD INFO    num_inter_threads:    0</span><br><span class="line">DEEPMD INFO    -----------------------------------------------------------------</span><br><span class="line">DEEPMD INFO    ---Summary of DataSystem: training     -----------------------------------------------</span><br><span class="line">DEEPMD INFO    found 1 system(s):</span><br><span class="line">DEEPMD INFO                                        system  natoms  bch_sz   n_bch   prob  pbc</span><br><span class="line">DEEPMD INFO                      ../00.data/training_data       5       7      23  1.000    T</span><br><span class="line">DEEPMD INFO    --------------------------------------------------------------------------------------</span><br><span class="line">DEEPMD INFO    ---Summary of DataSystem: validation   -----------------------------------------------</span><br><span class="line">DEEPMD INFO    found 1 system(s):</span><br><span class="line">DEEPMD INFO                                        system  natoms  bch_sz   n_bch   prob  pbc</span><br><span class="line">DEEPMD INFO                    ../00.data/validation_data       5       7       5  1.000    T</span><br><span class="line">DEEPMD INFO    --------------------------------------------------------------------------------------</span><br><span class="line">DEEPMD INFO    training without frame parameter</span><br><span class="line">DEEPMD INFO    data stating... (this step may take long time)</span><br><span class="line">OMP: Info #254: KMP_AFFINITY: pid 99 tid 99 thread 0 bound to OS proc set 0</span><br><span class="line">DEEPMD INFO    built lr</span><br><span class="line">DEEPMD INFO    built network</span><br><span class="line">DEEPMD INFO    built training</span><br><span class="line">WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.</span><br><span class="line">DEEPMD INFO    initialize model from scratch</span><br><span class="line">DEEPMD INFO    start training at lr 1.00e-03 (== 1.00e-03), decay_step 50, decay_rate 0.950006, final lr will be 3.51e-08</span><br><span class="line">DEEPMD INFO    batch     200 training time 11.42 s, testing time 0.24 s</span><br><span class="line">DEEPMD INFO    batch     400 training time 9.99 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch     600 training time 9.90 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch     800 training time 9.90 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    1000 training time 9.93 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    1200 training time 9.91 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    1400 training time 9.89 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    1600 training time 9.96 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    1800 training time 9.88 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    2000 training time 9.91 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    2200 training time 9.89 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    2400 training time 9.87 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    2600 training time 9.91 s, testing time 0.06 s</span><br><span class="line">DEEPMD INFO    batch    2800 training time 9.93 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    3000 training time 9.89 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    3200 training time 9.89 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    3400 training time 9.87 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    3600 training time 9.89 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    3800 training time 9.89 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    4000 training time 9.98 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    4200 training time 9.88 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    4400 training time 9.87 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    4600 training time 9.85 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    4800 training time 9.88 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    5000 training time 9.90 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    5200 training time 9.91 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    5400 training time 9.86 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    5600 training time 9.88 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    5800 training time 9.87 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    6000 training time 9.90 s, testing time 0.03 s</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use standard file APIs to delete files with this prefix.</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use standard file APIs to delete files with this prefix.</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    6200 training time 9.87 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    6400 training time 9.97 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    6600 training time 9.85 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    6800 training time 9.90 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    7000 training time 9.86 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    7200 training time 9.90 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    7400 training time 9.92 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    7600 training time 9.91 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    7800 training time 9.91 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    8000 training time 9.87 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    8200 training time 9.86 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    8400 training time 9.86 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    8600 training time 9.93 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    8800 training time 9.86 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    9000 training time 9.92 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    9200 training time 9.85 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch    9400 training time 9.89 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    9600 training time 9.84 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    batch    9800 training time 9.98 s, testing time 0.04 s</span><br><span class="line">DEEPMD INFO    batch   10000 training time 9.86 s, testing time 0.03 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    average training time: 0.0495 s/batch (exclude first 200 batches)</span><br><span class="line">DEEPMD INFO    finished training</span><br><span class="line">DEEPMD INFO    wall time: 509.976 s</span><br></pre></td></tr></table></figure><p>屏幕上会显示数据系统的信息，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DEEPMD INFO    -----------------------------------------------------------------</span><br><span class="line">DEEPMD INFO    ---Summary of DataSystem: training     ----------------------------------</span><br><span class="line">DEEPMD INFO    found 1 system(s):</span><br><span class="line">DEEPMD INFO                                 system  natoms  bch_sz   n_bch   prob  pbc</span><br><span class="line">DEEPMD INFO               ../00.data/training_data       5       7      23  1.000    T</span><br><span class="line">DEEPMD INFO    -------------------------------------------------------------------------</span><br><span class="line">DEEPMD INFO    ---Summary of DataSystem: validation   ----------------------------------</span><br><span class="line">DEEPMD INFO    found 1 system(s):</span><br><span class="line">DEEPMD INFO                                 system  natoms  bch_sz   n_bch   prob  pbc</span><br><span class="line">DEEPMD INFO             ../00.data/validation_data       5       7       5  1.000    T</span><br><span class="line">DEEPMD INFO    -------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>以及该训练的起始和最终学习率：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DEEPMD INFO    start training at lr 1.00e-03 (== 1.00e-03), decay_step 50, decay_rate 0.950006, final lr will be 3.51e-08</span><br></pre></td></tr></table></figure><p>如果一切正常，您将看到每 200 batch 打印的信息，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DEEPMD INFO    batch     200 training time 6.04 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch     400 training time 4.80 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch     600 training time 4.80 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch     800 training time 4.78 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch    1000 training time 4.77 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br><span class="line">DEEPMD INFO    batch    1200 training time 4.47 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch    1400 training time 4.49 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch    1600 training time 4.45 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch    1800 training time 4.44 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    batch    2000 training time 4.46 s, testing time 0.02 s</span><br><span class="line">DEEPMD INFO    saved checkpoint model.ckpt</span><br></pre></td></tr></table></figure><p>它们显示了训练和测试时间计数。在每 1000 batch 结束时，模型将保存在 Tensorflow 的 checkpoint 文件 <code>model.ckpt</code> 中。</p><p>同时，训练和测试误差将在文件<code>lcurve.out</code>中呈现。该文件包含 8 列，从左到右依次是：</p><ol><li>训练步数</li><li>验证损失</li><li>训练损失</li><li>能量的均方根（RMS）验证误差</li><li>能量的 RMS 训练误差</li><li>力的 RMS 验证误差</li><li>力的 RMS 训练误差</li><li>学习率</li></ol><p>学习率是机器学习中的一个重要概念。在 DP 模型中，学习率会经历一个 从大到小指数衰减的过程。这样既能保证模型收敛的效率，也能保证模型的精度。因此在学习率的参数中，有起始学习率(start_lr）和结束学习率（end_rate） 两种。在上面的例子中，我们将起始学习率、结束学习率和学习率的衰减步长分别设置为 0.001，3.51e-8，和 50，那么模型学习率会从 0.001 开始，每 50 步降低一点，直到降低到 3.51e-8（或者训练结束）为止。</p><h4 id="4-冻结模型">4 冻结模型</h4><p>在训练结束时，应该将保存在 TensorFlow 的 <code>checkpoint</code> 文件中的模型参数冻结为一个模型文件，通常以扩展名 .pb 结束。只需执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="comment"># 进入 DeePMD-kit_Tutorial/01.train/ 训练文件夹并冻结模型</span></span></span><br><span class="line">! cd DeePMD-kit_Tutorial/01.train/ &amp;&amp; dp freeze -o graph.pb</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">non-resource variables are not supported in the long term</span><br><span class="line">WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.</span><br><span class="line">WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0</span><br><span class="line">WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0</span><br><span class="line">/opt/deepmd-kit-2.2.1/lib/python3.10/importlib/__init__.py:169: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.</span><br><span class="line">  _bootstrap._exec(spec, module)</span><br><span class="line">2023-09-25 18:48:11.340773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#x27;libcuda.so.1&#x27;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64</span><br><span class="line">2023-09-25 18:48:11.340810: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)</span><br><span class="line">DEEPMD INFO    The following nodes will be frozen: [&#x27;model_type&#x27;, &#x27;descrpt_attr/rcut&#x27;, &#x27;descrpt_attr/ntypes&#x27;, &#x27;model_attr/tmap&#x27;, &#x27;model_attr/model_type&#x27;, &#x27;model_attr/model_version&#x27;, &#x27;train_attr/min_nbor_dist&#x27;, &#x27;train_attr/training_script&#x27;, &#x27;o_energy&#x27;, &#x27;o_force&#x27;, &#x27;o_virial&#x27;, &#x27;o_atom_energy&#x27;, &#x27;o_atom_virial&#x27;, &#x27;fitting_attr/dfparam&#x27;, &#x27;fitting_attr/daparam&#x27;]</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:354: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use `tf.compat.v1.graph_util.convert_variables_to_constants`</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:354: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use `tf.compat.v1.graph_util.convert_variables_to_constants`</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:925: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use `tf.compat.v1.graph_util.extract_sub_graph`</span><br><span class="line">WARNING:tensorflow:From /opt/deepmd-kit-2.2.1/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:925: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line">Use `tf.compat.v1.graph_util.extract_sub_graph`</span><br><span class="line">DEEPMD INFO    1211 ops in the final graph.</span><br></pre></td></tr></table></figure><p>它将在当前目录中输出一个名为 <em>graph.pb</em> 的模型文件。</p><p><span style="color:purple; font-weight:bold">到目前为止，我们就获得了一个使用 DeePMD-kit 通过高精度的从头算分子动力学数据获得的深度势能模型：<em>DeePMD-kit_Tutorial/01.train/graph.pb</em></span></p><h4 id="6-测试模型">6 测试模型</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! cd DeePMD-kit_Tutorial/01.train/ &amp;&amp; dp test -m graph.pb -s ../00.data/validation_data</span><br></pre></td></tr></table></figure><h4 id="7-使用LAMMPS进行MD计算">7 使用LAMMPS进行MD计算</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! cd ./DeePMD-kit_Tutorial/02.lmp &amp;&amp; lmp -i in.lammps</span><br></pre></td></tr></table></figure><p>其中<code>in.lammps</code>的pair_style将deepmd的输出模型 graph.pb作为输入。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> gas phase methane</span></span><br><span class="line"></span><br><span class="line">units           metal</span><br><span class="line">boundary        p p p</span><br><span class="line">atom_style      atomic</span><br><span class="line"></span><br><span class="line">neighbor        1.0 bin</span><br><span class="line">neigh_modify    every 10 delay 0 check no</span><br><span class="line"></span><br><span class="line">read_data       conf.lmp</span><br><span class="line">mass            1 1</span><br><span class="line">mass            2 12</span><br><span class="line"></span><br><span class="line">pair_style      deepmd graph.pb</span><br><span class="line">pair_coeff      * *</span><br><span class="line"></span><br><span class="line">velocity        all create 50.0 23456789</span><br><span class="line">fix             1 all nvt temp 50.0 50.0 0.5</span><br><span class="line">timestep        0.001</span><br><span class="line"></span><br><span class="line">thermo_style    custom step pe ke etotal temp press vol</span><br><span class="line">thermo          100</span><br><span class="line">dump            1 all custom 100 ch4.dump id type x y z</span><br><span class="line"></span><br><span class="line">run             5000</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;DeePMD-kit&quot;&gt;DeePMD-kit&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;给定第一性原理数据，训练深度势能模型
&lt;ul&gt;
&lt;li&gt;VASP&lt;/li&gt;
&lt;li&gt;CP2K&lt;/li&gt;
&lt;li&gt;QE&lt;/li&gt;
&lt;li&gt;ABACUS&lt;/li&gt;
&lt;li&gt;SIESTA&lt;/li&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MST</title>
    <link href="https://itachicheng.github.io/MST/"/>
    <id>https://itachicheng.github.io/MST/</id>
    <published>2024-05-12T09:54:28.000Z</published>
    <updated>2024-05-15T16:23:49.125Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>设计模式</title>
    <link href="https://itachicheng.github.io/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>https://itachicheng.github.io/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2023-12-19T16:38:53.758Z</published>
    <updated>2023-12-19T16:38:53.758Z</updated>
    
    <content type="html"><![CDATA[<p><img src="design_pattern.jpg" alt=""></p><h3 id="面向对象设计五大心法（The-Heart）">面向对象设计五大心法（The Heart）</h3><ul><li>The Single Responsibility Principle(单一职责原则)——SRP</li><li>The Open Closed Principle(开放封闭原则)——OCP</li><li>The Liskov Substitution Principle(Liskov替换原则)——LSP</li><li>The Interface Segregation Principle(接口隔离原则)——ISP</li><li>The Dependency Inversion Principle(依赖倒置原则)——DIP</li></ul><p><strong>SOLID = High Conhesion Loose Couple</strong></p><h4 id="单一职责原则">单一职责原则</h4><h5 id="6-Responsibilities-of-Object">6 Responsibilities of Object</h5><ul><li>Information holder<br>作为存储对象并提供对象信息给其他对象</li><li>Interfacer<br>在系统的各部分之间转化信息（或请求）</li><li>Structurer<br>维护对象之间的结构关系</li><li>Service provider<br>执行工作处理并提供给其他对象</li><li>Controller<br>控制决策一系列的任务处理</li><li>Coordinator<br>不作工作处理，只代理工作到其它对象上。</li></ul><h5 id="Rectangle-Class-Design-Question">Rectangle Class Design Question</h5><p>拆成两个部分，命令行应用程序只管计算，变化朝着依赖的反方向传递，永远要依赖于比较稳定的东西，之所以强调于依赖抽象，是因为抽象更加稳定。</p><p>SRP:What is Responsibility?<br>Responsibility = “a reason for change.”</p><h5 id="Modoem-Non-SRP-Design">Modoem Non-SRP Design</h5><p>Extract Class<br><strong>某个类做了应该由两个类做的事情</strong>，建立一个新类，将相关的值域和函数从旧类搬移到新类</p><p>CalculateRent()函数怎么写(没必要赌需求，哈哈哈，等需求来的时候再作设计，第一版怎么简单怎么写)</p><h4 id="开放封闭原则">开放封闭原则</h4><h3 id="重构的基本招式">重构的基本招式</h3><h4 id="Rename">Rename</h4><p>为什么要做Rename重构，软件生命周期的成本包含需求、设计、实现、测试和维护，其中维护占比最大。</p><h5 id="为名字加上单位">为名字加上单位</h5><ul><li>Start(int delay) --&gt; Start(int delay_secs)</li><li>CreateCache(int size) --&gt; CreateCache(int size_mb)</li><li>ThrottleDownload(float limit) --&gt; ThrottleDownload(float max_kbps)</li><li>Rotate(float angle) --&gt; Rotate(float degrees_cw)</li></ul><h5 id="附带其他重要属性">附带其他重要属性</h5><ul><li>password --&gt; plaintext_password 纯文本密码，需要加密</li><li>comment --&gt; unsecaped_comment 用户输入，需要转义</li><li>html --&gt; html_utf8 已经转换为UTF-8的html</li><li>data --&gt; data_urlenc 以url方式编码的数据</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;design_pattern.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;面向对象设计五大心法（The-Heart）&quot;&gt;面向对象设计五大心法（The Heart）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Single Responsibility Pr</summary>
      
    
    
    
    <category term="Software Engineering" scheme="https://itachicheng.github.io/categories/Software-Engineering/"/>
    
    
  </entry>
  
  <entry>
    <title>Class Diagram</title>
    <link href="https://itachicheng.github.io/Class%20Diagram/"/>
    <id>https://itachicheng.github.io/Class%20Diagram/</id>
    <published>2023-12-19T16:38:53.606Z</published>
    <updated>2023-12-19T16:38:53.606Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Class-Diagram">Class Diagram</h3><h4 id="需求分析">需求分析</h4><h5 id="基于用例（Use-Case-技术需求分析方法——识别Actor">基于用例（Use-Case)技术需求分析方法——识别Actor</h5><p>示例：识别考勤卡系统的参与者</p><p>输入信息：（客户）所有参与工时的员工，系统维护人员</p><p>参与者识别：公司员工，考勤卡系统维护人员</p><p>输入信息：每半个月用一个Excel表格来记录，每个员工将他的工时表格，用电子邮件发给<strong>我</strong>。这个表格有固定的格式…</p><p>参与者识别：公司员工，考勤管理人员</p><p>输入信息：（客户）对考勤异常的员工，系统会实时发出异常提醒，定期会对全部考勤数据进行统计分析。</p><p>参与者识别：公司员工、考勤管理人员（隐含）、考勤分析人员（隐含）</p><h5 id="基于用例（Use-Case-技术需求分析方法——识别用例">基于用例（Use-Case)技术需求分析方法——识别用例</h5><ul><li>识别用例（Use-Case)<ul><li>用例是系统执行的一系列动作，这些动作将生成特定参与者可观测的价值结果</li><li>一个用例能表达从触发到完成有意义目标的完整的系统执行过程</li><li>一个用例定义一组用例实例</li></ul></li><li>关于用例的几点说明<ul><li>Use Case不是需求片段</li><li>Use Case不是系统内部功能、模块</li><li>用例可以是一个场景，包括动作和交互</li><li>用例可以是一组场景，描述不同场景下的行为</li></ul></li></ul><h5 id="基于用例（Use-Case-技术需求分析方法——描述用例">基于用例（Use-Case)技术需求分析方法——描述用例</h5><ul><li>前置、后置条件（状态，系统可检测）<ul><li>前置条件约束用例开始前系统的状态</li><li>后置条件约束用例执行后系统的状态</li><li>某些用例依赖于其他用例</li><li>有助于识别漏掉的用例</li></ul></li></ul><p>考勤卡系统的用例描述</p><table><thead><tr><th><strong>用例内容</strong></th><th>内容解释</th><th>写作举例</th></tr></thead><tbody><tr><td>用例名称</td><td>给用例一个名称</td><td>记录员工工时</td></tr><tr><td>用例编号</td><td>便于管理</td><td>XXX.YYY.ZZZ.001</td></tr><tr><td>简要说明</td><td>用例的概要描述</td><td>员工刷卡后自动记录工时</td></tr><tr><td>Actor</td><td>用例的所有Actor</td><td>员工</td></tr><tr><td>前置条件</td><td>启动系统前，系统必须满足的条件</td><td>系统管理员已启动系统，前端显示界面</td></tr><tr><td>最小保证</td><td>用例对系统的最低要求</td><td>工时系统在PC上稳定运行，读卡器正常工作</td></tr><tr><td>后置条件</td><td>用例完成后，系统输出或达到的状态</td><td>如果员工刷卡，则记录本次刷卡时间</td></tr><tr><td>触发事件</td><td>启动用例的事件</td><td>当员工刷卡时，触发用例</td></tr><tr><td>基本场景</td><td>完成用例目标需要的一系列基本动作</td><td>1. 员工刷卡，读卡器读取员工信息，输入到系统；2.系统获得刷卡时间，并将员工刷卡信息录入系统；3.系统将员工刷卡信息持久化；4.界面显示员工刷卡信息</td></tr><tr><td>扩展场景</td><td>非基本的成功场景和失败场景</td><td>1.员工不存在；2.如果员工刷卡方式不正确，导致读卡器工卡信息，提示重新刷卡；3.如果工时系统运行出现故障，系统故障</td></tr><tr><td>DFX</td><td>该用例涉及的DFX属性的要求和各架构的目标</td><td>1.员工刷卡后，0.5秒内在界面显示刷新信息；2.已刷卡成功的员工信息，系统重启后，不丢失；3.界面风格可换</td></tr></tbody></table><h5 id="需求管理">需求管理</h5><p>需求不断变化，开发过程中最痛苦的事莫过于此（需求不稳定），需求变化了，设计规格也更新了，但是没有及时知会到开发（需求传递不及时），作为资深测试人员，还时常和开发人员对同一需求的理解不在一个频道（需求描述不准确），需求分解不充分，一边分析一边开发。</p><p>产品：初始需求（IR）研发：系统需求（SR）-分配需求（AR）</p><p>需求管理流程：需求收集——需求分析（需求分析团队RAT评审）——需求决策（需求管理团队RMT）——需求实现——需求验证</p><p>需求管理活动：变更控制、版本控制、状态跟踪、需求跟踪（将每项需求都能与对应的设计、源代码、测试用例联系起来，以实现需求的跟踪）</p><h4 id="association-and-dependency">association and dependency</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@startuml</span><br><span class="line">skinparam classAttributeIconSize 0</span><br><span class="line">class ClassA&#123;</span><br><span class="line"></span><br><span class="line">- classB : ClassB</span><br><span class="line">&#125;</span><br><span class="line">ClassA ..&gt; ClassB</span><br><span class="line"></span><br><span class="line">class ClassC&#123;</span><br><span class="line"></span><br><span class="line">+ depend(ClassD classD)</span><br><span class="line">&#125;</span><br><span class="line">ClassC --&gt; ClassD</span><br><span class="line">@enduml</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以上两种关系代表关联和依赖，其中关联的耦合度强于依赖。在类的层次结构表达上，关联体现在ClassA含有成员变量ClassB，而依赖体现在ClassC中的方法需要ClassD作为参数传入。</p><h4 id=""></h4>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Class-Diagram&quot;&gt;Class Diagram&lt;/h3&gt;
&lt;h4 id=&quot;需求分析&quot;&gt;需求分析&lt;/h4&gt;
&lt;h5 id=&quot;基于用例（Use-Case-技术需求分析方法——识别Actor&quot;&gt;基于用例（Use-Case)技术需求分析方法——识别Actor&lt;/</summary>
      
    
    
    
    <category term="Software Engineering" scheme="https://itachicheng.github.io/categories/Software-Engineering/"/>
    
    
  </entry>
  
  <entry>
    <title>Non-deterministic_Polynomial</title>
    <link href="https://itachicheng.github.io/Non-deterministic-Polynomial/"/>
    <id>https://itachicheng.github.io/Non-deterministic-Polynomial/</id>
    <published>2022-09-16T13:55:15.000Z</published>
    <updated>2023-12-19T16:38:53.715Z</updated>
    
    <content type="html"><![CDATA[<h3 id="多项式时间的算法">多项式时间的算法</h3><p>对于规模为n的输入，在最坏情况下的运行时间是O(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">n^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span>)，k为某一确定的常数，也称P类问题。并不是所有问题都可以在多项式时间内解决。</p><p>图灵停机问题</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">H</span><span class="params">(procedure, Input)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">U</span><span class="params">(P)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// H(P,P) == 0时则跳出循环，程序正常结束；H(P,P)==1时则进入死循环中。</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">H</span>(P, P))&#123;&#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问是否存在过程H(P,I)可以判断对于程序P在输入I的情况下是否可停机。构造出U§这个函数可以导出矛盾：</p><ul><li>假设H(U, U)输出“停机” -&gt; U(U)进入死循环，但此时H(U, U)代表程序U在输入为U的情况下判定输出为“停机”。</li><li>假设H(U, U)输出死循环 -&gt; U(U)停机：两者一样矛盾。</li></ul><p>同样的还有“理发师悖论”和“停机测试悖论”，本质上来讲，这是递归过程中对象重叠的成环效应。</p><script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script><script>mermaid.initialize({startOnLoad:true});</script><div class="mermaid">graph TD;    A(自己理发的理发师)-->|触发'不理发'|B(不自己理发的理发师);    B-->|触发'理发'|A'(自己理发的理发师);    A'--> ...</div><p>我们无法确定“理发师”究竟是属于“自己理发”还是“不自己理发”的状态，只能通过扩充维度（时间）来说，“诶，这个理发师有一段时间是自己理发的”，“呀，这个理发师这几个月没有自己理发”，因而计算机无法在多项式时间内求得一个确定的解。</p><div class="mermaid">graph TD;    A(自己理发的理发师)-->|触发'不理发'|B(不自己理发的理发师);    B-->|触发'理发'|A(自己理发的理发师);</div><h3 id="NP问题">NP问题</h3><p>NP类问题是指在多项式时间内可以被证明的问题。对于Hamilton回路，在给定的有向图G=(V,E)中，如果给定一个问题解的证书（相当于一个正解的表示形式），我们可以在O(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">n^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>)的时间内验证这个证书。例如，证书是一个含有|V|个顶点的序列，&lt;<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">v_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,…,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{|V|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span>&gt;,可以轻易地证明(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">v_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo></mrow><annotation encoding="application/x-tex">\in</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">∈</span></span></span></span> E(其中i=1,2,3,4,…,|V|-1),同样也可以证明(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{|V|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">v_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo></mrow><annotation encoding="application/x-tex">\in</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">∈</span></span></span></span> E。</p><h3 id="NP-hard问题">NP-hard问题</h3><p>NP-hard有一个性质是 L <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo mathvariant="normal">∉</mo></mrow><annotation encoding="application/x-tex">\notin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mrel"><span class="mord"><span class="mrel">∈</span></span><span class="mord vbox"><span class="thinbox"><span class="llap"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="inner"><span class="mord"><span class="mord">/</span><span class="mspace" style="margin-right:0.0556em;"></span></span></span><span class="fix"></span></span></span></span></span></span></span></span> NP。寻找一些能够在多项式时间内得到近似最优解的方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;多项式时间的算法&quot;&gt;多项式时间的算法&lt;/h3&gt;
&lt;p&gt;对于规模为n的输入，在最坏情况下的运行时间是O(&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/199</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Markdown</title>
    <link href="https://itachicheng.github.io/Markdown/"/>
    <id>https://itachicheng.github.io/Markdown/</id>
    <published>2022-09-16T13:52:00.000Z</published>
    <updated>2023-12-19T16:38:53.611Z</updated>
    
    <content type="html"><![CDATA[<h3 id="With-Mermaid">With Mermaid</h3><p>VS Code插件 Markdown Preview Mermaid Support</p><p>官网地址： <a href="https://mermaid-js.github.io/mermaid/#/">https://mermaid-js.github.io/mermaid/#/</a></p><p>部署方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=&#x27;https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js&#x27;&gt;&lt;/script&gt;</span><br><span class="line">&lt;script&gt;mermaid.initialize(&#123;startOnLoad:true&#125;);&lt;/script&gt;</span><br><span class="line">&lt;div class=&quot;mermaid&quot;&gt;</span><br><span class="line">gitGraph</span><br><span class="line">    commit</span><br><span class="line">    commit</span><br><span class="line">    branch develop</span><br><span class="line">    commit</span><br><span class="line">    commit</span><br><span class="line">    commit</span><br><span class="line">    checkout main</span><br><span class="line">    commit</span><br><span class="line">    commit</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script><script>mermaid.initialize({startOnLoad:true});</script><div class="mermaid">gitGraph    commit    commit    branch develop    commit    commit    commit    checkout main    commit    commit</div><p>以下内容转自链接：<a href="https://www.jianshu.com/p/e74eb43960a1">https://www.jianshu.com/p/e74eb43960a1</a></p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">行内公式：将公式插入到本行内，符号：$公式内容$，如：$xyz$</span><br><span class="line">独行公式：将公式插入到新的一行内，并且居中，符号：$$公式内容$$，如：$$xyz$$</span><br><span class="line"></span><br><span class="line">上标符号，符号：^，如：$x^4$</span><br><span class="line">下标符号，符号：<span class="emphasis">_，如：$x_</span>1$</span><br><span class="line">组合符号，符号：&#123;&#125;，如：$&#123;16&#125;<span class="emphasis">_&#123;8&#125;O&#123;2+&#125;_</span>&#123;2&#125;$</span><br><span class="line"></span><br><span class="line">字体控制，符号：\displaystyle，如：$\displaystyle \frac&#123;x+y&#125;&#123;y+z&#125;$</span><br><span class="line">下划线符号，符号：\underline，如：$\underline&#123;x+y&#125;$</span><br><span class="line">上大括号，符号：\overbrace&#123;算式&#125;，如：$\overbrace&#123;a+b+c+d&#125;^&#123;2.0&#125;$</span><br><span class="line">下大括号，符号：\underbrace&#123;算式&#125;，如：$a+\underbrace&#123;b+c&#125;<span class="emphasis">_&#123;1.0&#125;+d$</span></span><br><span class="line"><span class="emphasis">上位符号，符号：\stacrel&#123;上位符号&#125;&#123;基位符号&#125;，如：$\vec&#123;x&#125;\stackrel&#123;\mathrm&#123;def&#125;&#125;&#123;=&#125;&#123;x_</span>1,\dots,x<span class="emphasis">_n&#125;$</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">希腊字母</span></span><br><span class="line"><span class="emphasis">字母实现字母实现</span></span><br><span class="line"><span class="emphasis">AAα\alhpa</span></span><br><span class="line"><span class="emphasis">BBβ\beta</span></span><br><span class="line"><span class="emphasis">Γ\Gammaγ\gamma</span></span><br><span class="line"><span class="emphasis">Δ\Deltaδ\delta</span></span><br><span class="line"><span class="emphasis">EEϵ\epsilon</span></span><br><span class="line"><span class="emphasis">ZZζ\zeta</span></span><br><span class="line"><span class="emphasis">HHη\eta</span></span><br><span class="line"><span class="emphasis">Θ\Thetaθ\theta</span></span><br><span class="line"><span class="emphasis">IIι\iota</span></span><br><span class="line"><span class="emphasis">KKκ\kappa</span></span><br><span class="line"><span class="emphasis">Λ\Lambdaλ\lambda</span></span><br><span class="line"><span class="emphasis">MMμ\mu</span></span><br><span class="line"><span class="emphasis">NNν\nu</span></span><br><span class="line"><span class="emphasis">Ξ\Xiξ\xi</span></span><br><span class="line"><span class="emphasis">OOο\omicron</span></span><br><span class="line"><span class="emphasis">Π\Piπ\pi</span></span><br><span class="line"><span class="emphasis">PPρ\rho</span></span><br><span class="line"><span class="emphasis">Σ\Sigmaσ\sigma</span></span><br><span class="line"><span class="emphasis">TTτ\tau</span></span><br><span class="line"><span class="emphasis">Υ\Upsilonυ\upsilon</span></span><br><span class="line"><span class="emphasis">Φ\Phiϕ\phi</span></span><br><span class="line"><span class="emphasis">XXχ\chi</span></span><br><span class="line"><span class="emphasis">Ψ\Psiψ\psi</span></span><br><span class="line"><span class="emphasis">Ω\vω\omega</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">占位符</span></span><br><span class="line"><span class="emphasis">两个quad空格，符号：\qquad，如：$x \qquad y$</span></span><br><span class="line"><span class="emphasis">quad空格，符号：\quad，如：$x \quad y$</span></span><br><span class="line"><span class="emphasis">大空格，符号\，如：$x \ y$</span></span><br><span class="line"><span class="emphasis">中空格，符号\:，如：$x : y$</span></span><br><span class="line"><span class="emphasis">小空格，符号\,，如：$x , y$</span></span><br><span class="line"><span class="emphasis">没有空格，符号``，如：$xy$</span></span><br><span class="line"><span class="emphasis">紧贴，符号\!，如：$x ! y$</span></span><br><span class="line"><span class="emphasis">定界符与组合</span></span><br><span class="line"><span class="emphasis">括号，符号：（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)，如：$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$</span></span><br><span class="line"><span class="emphasis">中括号，符号：[]，如：$[x+y]$</span></span><br><span class="line"><span class="emphasis">大括号，符号：\&#123; \&#125;，如：$&#123;x+y&#125;$</span></span><br><span class="line"><span class="emphasis">自适应括号，符号：\left \right，如：$\left(x\right)$，$\left(x&#123;yz&#125;\right)$</span></span><br><span class="line"><span class="emphasis">组合公式，符号：&#123;上位公式 \choose 下位公式&#125;，如：$&#123;n+1 \choose k&#125;=&#123;n \choose k&#125;+&#123;n \choose k-1&#125;$</span></span><br><span class="line"><span class="emphasis">组合公式，符号：&#123;上位公式 \atop 下位公式&#125;，如：$\sum_</span>&#123;k<span class="emphasis">_0,k_</span>1,\ldots&gt;0 \atop k<span class="emphasis">_0+k_</span>1+\cdots=n&#125;A<span class="emphasis">_&#123;k_</span>0&#125;A<span class="emphasis">_&#123;k_</span>1&#125;\cdots$</span><br><span class="line">四则运算</span><br><span class="line">加法运算，符号：+，如：$x+y=z$</span><br><span class="line">减法运算，符号：-，如：$x-y=z$</span><br><span class="line">加减运算，符号：\pm，如：$x \pm y=z$</span><br><span class="line">减甲运算，符号：\mp，如：$x \mp y=z$</span><br><span class="line">乘法运算，符号：\times，如：$x \times y=z$</span><br><span class="line">点乘运算，符号：\cdot，如：$x \cdot y=z$</span><br><span class="line">星乘运算，符号：\ast，如：$x \ast y=z$</span><br><span class="line">除法运算，符号：\div，如：$x \div y=z$</span><br><span class="line">斜法运算，符号：/，如：$x/y=z$</span><br><span class="line">分式表示，符号：\frac&#123;分子&#125;&#123;分母&#125;，如：$\frac&#123;x+y&#125;&#123;y+z&#125;$</span><br><span class="line">分式表示，符号：&#123;分子&#125; \voer &#123;分母&#125;，如：$&#123;x+y&#125; \over &#123;y+z&#125;$</span><br><span class="line">绝对值表示，符号：||，如：$|x+y|$</span><br><span class="line">高级运算</span><br><span class="line">平均数运算，符号：\overline&#123;算式&#125;，如：$\overline&#123;xyz&#125;$</span><br><span class="line">开二次方运算，符号：\sqrt，如：$\sqrt x$</span><br><span class="line">开方运算，符号：\sqrt[开方数]&#123;被开方数&#125;，如：$\sqrt[3]&#123;x+y&#125;$</span><br><span class="line">对数运算，符号：\log，如：$\log(x)$</span><br><span class="line">极限运算，符号：\lim，如：$\lim^&#123;x \to \infty&#125;<span class="emphasis">_&#123;y \to 0&#125;&#123;\frac&#123;x&#125;&#123;y&#125;&#125;$</span></span><br><span class="line"><span class="emphasis">极限运算，符号：\displaystyle \lim，如：$\displaystyle \lim^&#123;x \to \infty&#125;_</span>&#123;y \to 0&#125;&#123;\frac&#123;x&#125;&#123;y&#125;&#125;$</span><br><span class="line">求和运算，符号：\sum，如：$\sum^&#123;x \to \infty&#125;<span class="emphasis">_&#123;y \to 0&#125;&#123;\frac&#123;x&#125;&#123;y&#125;&#125;$</span></span><br><span class="line"><span class="emphasis">求和运算，符号：\displaystyle \sum，如：$\displaystyle \sum^&#123;x \to \infty&#125;_</span>&#123;y \to 0&#125;&#123;\frac&#123;x&#125;&#123;y&#125;&#125;$</span><br><span class="line">积分运算，符号：\int，如：$\int^&#123;\infty&#125;<span class="emphasis">_&#123;0&#125;&#123;xdx&#125;$</span></span><br><span class="line"><span class="emphasis">积分运算，符号：\displaystyle \int，如：$\displaystyle \int^&#123;\infty&#125;_</span>&#123;0&#125;&#123;xdx&#125;$</span><br><span class="line">微分运算，符号：\partial，如：$\frac&#123;\partial x&#125;&#123;\partial y&#125;$</span><br><span class="line">矩阵表示，符号：\begin&#123;matrix&#125; \end&#123;matrix&#125;，如：$\left[ \begin&#123;matrix&#125; 1 &amp;2 &amp;\cdots &amp;4\5 &amp;6 &amp;\cdots &amp;8\\vdots &amp;\vdots &amp;\ddots &amp;\vdots\13 &amp;14 &amp;\cdots &amp;16\end&#123;matrix&#125; \right]$</span><br><span class="line">逻辑运算</span><br><span class="line">等于运算，符号：=，如：$x+y=z$</span><br><span class="line">大于运算，符号：&gt;，如：$x+y&gt;z$</span><br><span class="line">小于运算，符号：&lt;，如：$x+y<span class="xml">&lt;z$</span></span><br><span class="line"><span class="xml">大于等于运算，符号：\geq，如：$x+y \geq z$</span></span><br><span class="line"><span class="xml">小于等于运算，符号：\leq，如：$x+y \leq z$</span></span><br><span class="line"><span class="xml">不等于运算，符号：\neq，如：$x+y \neq z$</span></span><br><span class="line"><span class="xml">不大于等于运算，符号：\ngeq，如：$x+y \ngeq z$</span></span><br><span class="line"><span class="xml">不大于等于运算，符号：\not\geq，如：$x+y \not\geq z$</span></span><br><span class="line"><span class="xml">不小于等于运算，符号：\nleq，如：$x+y \nleq z$</span></span><br><span class="line"><span class="xml">不小于等于运算，符号：\not\leq，如：$x+y \not\leq z$</span></span><br><span class="line"><span class="xml">约等于运算，符号：\approx，如：$x+y \approx z$</span></span><br><span class="line"><span class="xml">恒定等于运算，符号：\equiv，如：$x+y \equiv z$</span></span><br><span class="line"><span class="xml">集合运算</span></span><br><span class="line"><span class="xml">属于运算，符号：\in，如：$x \in y$</span></span><br><span class="line"><span class="xml">不属于运算，符号：\notin，如：$x \notin y$</span></span><br><span class="line"><span class="xml">不属于运算，符号：\not\in，如：$x \not\in y$</span></span><br><span class="line"><span class="xml">子集运算，符号：\subset，如：$x \subset y$</span></span><br><span class="line"><span class="xml">子集运算，符号：\supset，如：$x \supset y$</span></span><br><span class="line"><span class="xml">真子集运算，符号：\subseteq，如：$x \subseteq y$</span></span><br><span class="line"><span class="xml">非真子集运算，符号：\subsetneq，如：$x \subsetneq y$</span></span><br><span class="line"><span class="xml">真子集运算，符号：\supseteq，如：$x \supseteq y$</span></span><br><span class="line"><span class="xml">非真子集运算，符号：\supsetneq，如：$x \supsetneq y$</span></span><br><span class="line"><span class="xml">非子集运算，符号：\not\subset，如：$x \not\subset y$</span></span><br><span class="line"><span class="xml">非子集运算，符号：\not\supset，如：$x \not\supset y$</span></span><br><span class="line"><span class="xml">并集运算，符号：\cup，如：$x \cup y$</span></span><br><span class="line"><span class="xml">交集运算，符号：\cap，如：$x \cap y$</span></span><br><span class="line"><span class="xml">差集运算，符号：\setminus，如：$x \setminus y$</span></span><br><span class="line"><span class="xml">同或运算，符号：\bigodot，如：$x \bigodot y$</span></span><br><span class="line"><span class="xml">同与运算，符号：\bigotimes，如：$x \bigotimes y$</span></span><br><span class="line"><span class="xml">实数集合，符号：\mathbb&#123;R&#125;，如：\mathbb&#123;R&#125;</span></span><br><span class="line"><span class="xml">自然数集合，符号：\mathbb&#123;Z&#125;，如：\mathbb&#123;Z&#125;</span></span><br><span class="line"><span class="xml">空集，符号：\emptyset，如：$\emptyset$</span></span><br><span class="line"><span class="xml">数学符号</span></span><br><span class="line"><span class="xml">无穷，符号：\infty，如：$\infty$</span></span><br><span class="line"><span class="xml">虚数，符号：\imath，如：$\imath$</span></span><br><span class="line"><span class="xml">虚数，符号：\jmath，如：$\jmath$</span></span><br><span class="line"><span class="xml">数学符号，符号\hat&#123;a&#125;，如：$\hat&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\check&#123;a&#125;，如：$\check&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\breve&#123;a&#125;，如：$\breve&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\tilde&#123;a&#125;，如：$\tilde&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\bar&#123;a&#125;，如：$\bar&#123;a&#125;$</span></span><br><span class="line"><span class="xml">矢量符号，符号\vec&#123;a&#125;，如：$\vec&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\acute&#123;a&#125;，如：$\acute&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\grave&#123;a&#125;，如：$\grave&#123;a&#125;$</span></span><br><span class="line"><span class="xml">数学符号，符号\mathring&#123;a&#125;，如：$\mathring&#123;a&#125;$</span></span><br><span class="line"><span class="xml">一阶导数符号，符号\dot&#123;a&#125;，如：$\dot&#123;a&#125;$</span></span><br><span class="line"><span class="xml">二阶导数符号，符号\ddot&#123;a&#125;，如：$\ddot&#123;a&#125;$</span></span><br><span class="line"><span class="xml">上箭头，符号：\uparrow，如：$\uparrow$</span></span><br><span class="line"><span class="xml">上箭头，符号：\Uparrow，如：$\Uparrow$</span></span><br><span class="line"><span class="xml">下箭头，符号：\downarrow，如：$\downarrow$</span></span><br><span class="line"><span class="xml">下箭头，符号：\Downarrow，如：$\Downarrow$</span></span><br><span class="line"><span class="xml">左箭头，符号：\leftarrow，如：$\leftarrow$</span></span><br><span class="line"><span class="xml">左箭头，符号：\Leftarrow，如：$\Leftarrow$</span></span><br><span class="line"><span class="xml">右箭头，符号：\rightarrow，如：$\rightarrow$</span></span><br><span class="line"><span class="xml">右箭头，符号：\Rightarrow，如：$\Rightarrow$</span></span><br><span class="line"><span class="xml">底端对齐的省略号，符号：\ldots，如：$1,2,\ldots,n$</span></span><br><span class="line"><span class="xml">中线对齐的省略号，符号：\cdots，如：$x_1^2 + x_2^2 + \cdots + x_n^2$</span></span><br><span class="line"><span class="xml">竖直对齐的省略号，符号：\vdots，如：$\vdots$</span></span><br><span class="line"><span class="xml">斜对齐的省略号，符号：\ddots，如：$\ddots$</span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"></span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;With-Mermaid&quot;&gt;With Mermaid&lt;/h3&gt;
&lt;p&gt;VS Code插件 Markdown Preview Mermaid Support&lt;/p&gt;
&lt;p&gt;官网地址： &lt;a href=&quot;https://mermaid-js.github.io/mer</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Cookbook</title>
    <link href="https://itachicheng.github.io/cookbook/"/>
    <id>https://itachicheng.github.io/cookbook/</id>
    <published>2022-08-07T03:05:14.000Z</published>
    <updated>2025-05-30T10:56:51.121Z</updated>
    
    <content type="html"><![CDATA[<h3 id="蒜香虾仁技术总结（源自美食作家王刚）">蒜香虾仁技术总结（源自美食作家王刚）</h3><ul><li>鲜虾500g冰箱急冻40分钟</li></ul><ol><li>方便前段剥壳，挤出虾尾，防止壳肉粘连；</li><li>挑出虾线去除杂质；</li><li>放入盆中清洗，清洗之后将其横刀切成两片备用；</li></ol><p><img src="suanrong_1.jpg" alt=""></p><ul><li>开始腌制</li></ul><ol><li>适量料酒（约3克）；</li><li>适量生抽酱油（约3克）；</li><li>食用盐半勺；</li><li>少许胡椒粉；</li><li>适量的白糖搅拌均匀；</li><li>加入处理好的虾仁搅拌均匀，中途加入适量的玉米淀粉拌匀腌制五分钟；</li></ol><p><img src="suanrong_2.jpg" alt=""></p><ul><li>准备辅料</li></ul><ol><li>大蒜100克拍散剁碎备用，最好能剁碎一些；</li><li>准备蒜苗1根，取下蒜叶之后切碎备用；</li><li>二荆条和小米辣切碎备用；</li></ol><ul><li>开始制作</li></ul><ol><li>在锅中加入适量的清水，然后加入蒜蓉焯水，将其烧开后再捞出，目的是煮熟和去除蒜蓉里面的淀粉，防止炸糊；<br><img src="suanrong_3.jpg" alt=""></li><li>加入适量的油烧热，加入淀粉炸香炸黄，淡黄色即可捞出；</li><li>留下少许炸蒜蓉的油烧热，然后将腌制好的虾仁下锅煎熟，中途翻面；</li><li>煎熟之后加入料头和蒜蓉翻炒均匀；</li></ol><p><img src="suanrong_4.jpg" alt=""></p><ul><li>出锅装盘</li></ul><p><img src="suanrong_5.jpg" alt=""></p><h3 id="水煮肉片技术总结（改编自美食作家王刚）">水煮肉片技术总结（改编自美食作家王刚）</h3><p>此篇记录省略了“刀口辣椒”的制作。</p><ul><li>准备猪肉并腌制</li></ul><ol><li>猪里脊肉300克，切成2mm薄片放入碗中清洗两遍，去除肉片中的血水和杂质；</li><li>碗中加入食用盐一勺，加入胡椒粉一克，加入生抽酱油5克，加入料酒3克朝着一个方向搅拌两分钟；</li><li>调鸡蛋糊，碗中加入鸡蛋清一个，加入三勺土豆淀粉，搅拌均匀；</li><li>鸡蛋糊和肉片一起搅拌均匀，形成锁水的润滑膜；</li><li>加入植物油拌匀备用；</li></ol><ul><li>准备辅料</li></ul><ol><li>准备油麦菜一颗，切三段备用；</li><li>准备芹菜几根，切成小段备用；</li><li>准备蒜苗两根轻轻拍散，切成小段备用；</li><li>准备大蒜20克，切碎备用，准备生姜切片备用；</li></ol><ul><li><p>准备刀口辣椒（省略，直接用老干妈代替）</p></li><li><p>开始制作</p></li></ul><ol><li>加入适量的底油，油温6成热后加入配菜爆炒20秒，炒至断生；</li><li>再次加入适量的底油，油温6成热后加入辅料和老干妈，开大火爆炒料头爆香；</li><li>然后加入清水烧开，将腌制好的肉片下锅，烫熟之后捞出摆盘；</li><li>肉片和配菜装盘后加入适量的原汤；</li></ol><h3 id="葱香牛肉技术总结（源自美食作家王刚）">葱香牛肉技术总结（源自美食作家王刚）</h3><ul><li>主料</li></ul><ol><li>外脊牛肉（350克）<ul><li>切成8mm薄片，横竖敲打备用；<br><img src="shuizhuniurou_1.jpg" alt=""><br><img src="shuizhuniurou_2.jpg" alt=""></li><li>清洗去除血水；<br><img src="shuizhuniurou_3.jpg" alt=""></li></ul></li></ol><ul><li>辅料</li></ul><ol><li>玉米淀粉（约2克）</li><li>土豆淀粉（15克）</li><li>植物油（适量）</li><li>大葱（120克）</li><li>大红椒（1个）</li><li>生姜（25克）</li><li>大蒜（几颗）</li><li>水淀粉（适量）</li></ol><ul><li>调味料</li></ul><ol><li><p>蚝油（适量）</p></li><li><p>生抽酱油（适量）</p></li><li><p>食用盐（少许）</p></li><li><p>老抽（适量）</p><ul><li>腌制牛肉，耗油三克，生成酱油三克，食用盐1.5克，老抽三克，清水15克；<br><img src="shuizhuniurou_5.jpg" alt=""></li></ul></li></ol><h3 id="家常豆腐（懒人烧豆腐加王刚版家常豆腐）">家常豆腐（懒人烧豆腐加王刚版家常豆腐）</h3><ul><li>准备原料</li></ul><ol><li>五花肉（16yuan/斤）</li><li>蒜叶（7yuan/斤）</li><li>老豆腐（4yuan/jin）<br><img src="jiachangdoufu_2.jpg" alt=""></li></ol><ul><li>准备调料</li></ul><ol><li>生抽三克</li><li>食盐1.5克</li><li>白糖1.5克</li><li>淀粉适量<br><img src="jiachangdoufu_1.jpg" alt=""></li></ol><ul><li><p>开始制作<br><img src="jiachangdoufu_3.jpg" alt=""></p><ul><li><p>技术难点</p><p>豆腐煎6分钟后第一次翻面，非常考验对锅的控制，不少豆腐挤成一团，如上所示；</p></li></ul></li><li><p>成品展示</p></li></ul><p><img src="jiachangdoufu_4.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;蒜香虾仁技术总结（源自美食作家王刚）&quot;&gt;蒜香虾仁技术总结（源自美食作家王刚）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;鲜虾500g冰箱急冻40分钟&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;方便前段剥壳，挤出虾尾，防止壳肉粘连；&lt;/li&gt;
&lt;li&gt;挑出虾线去除杂质；&lt;/li&gt;
</summary>
      
    
    
    
    <category term="Life" scheme="https://itachicheng.github.io/categories/Life/"/>
    
    
    <category term="Autobiography" scheme="https://itachicheng.github.io/tags/Autobiography/"/>
    
  </entry>
  
</feed>
