<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Ascend | 图灵先生的光</title><meta name="author" content="ChengQiang"><meta name="copyright" content="ChengQiang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Host与Device  Host指与Device相连的X86服务器、ARM服务器，会利用Device提供的NN（Neural Network）计算能力完成任务 Device模块指安装了昇腾AI处理器的硬件设备，利用PCIe接口与Host侧连接，提供NN计算能力  核函数 核函数（Kernel Fu"><link rel="shortcut icon" href="/img/Ulchiha.png"><link rel="canonical" href="https://itachicheng.github.io/Ascend/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.14.0-b3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.35/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>(()=>{
      const saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
      
      window.btf = {
        saveToLocal: saveToLocal,
        getScript: (url, attr = {}) => new Promise((resolve, reject) => {
          const script = document.createElement('script')
          script.src = url
          script.async = true
          script.onerror = reject
          script.onload = script.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            script.onload = script.onreadystatechange = null
            resolve()
          }

          Object.keys(attr).forEach(key => {
            script.setAttribute(key, attr[key])
          })

          document.head.appendChild(script)
        }),

        getCSS: (url, id = false) => new Promise((resolve, reject) => {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = url
          if (id) link.id = id
          link.onerror = reject
          link.onload = link.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            link.onload = link.onreadystatechange = null
            resolve()
          }
          document.head.appendChild(link)
        }),

        addGlobalFn: (key, fn, name = false, parent = window) => {
          const pjaxEnable = false
          if (!pjaxEnable && key.startsWith('pjax')) return

          const globalFn = parent.globalFn || {}
          const keyObj = globalFn[key] || {}
    
          if (name && keyObj[name]) return
    
          name = name || Object.keys(keyObj).length
          keyObj[name] = fn
          globalFn[key] = keyObj
          parent.globalFn = globalFn
        }
      }
    
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode
      
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ascend',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-08-04 16:37:39'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="图灵先生的光" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/loopy2.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="图灵先生的光"><span class="site-name">图灵先生的光</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Ascend</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-05-29T15:40:00.000Z" title="Created 2025-05-30 01:40:00">2025-05-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-08-04T06:37:39.021Z" title="Updated 2025-08-04 16:37:39">2025-08-04</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Ascend"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="Host与Device">Host与Device</h3>
<ul>
<li>Host指与Device相连的X86服务器、ARM服务器，会利用Device提供的NN（Neural Network）计算能力完成任务</li>
<li>Device模块指安装了昇腾AI处理器的硬件设备，利用PCIe接口与Host侧连接，提供NN计算能力</li>
</ul>
<h3 id="核函数">核函数</h3>
<p>核函数（Kernel Function）是Ascend C算子device侧的入口。Ascend C允许用户使用核函数这种C/C++的语法扩展来运行device代码。用户在核函数中实现算子逻辑的编写，例如自定义算子类及其成员函数以实现该算子的所有功能。</p>
<p><strong>核函数</strong>是直接在device侧执行的代码。在核函数中，需要为在一个核上执行的代码规定要进行的<strong>数据访问</strong>和<strong>计算操作</strong>，SPMD编程模型允许核函数调用时，多个核并行地执行同一个计算任务。</p>
<p>核函数是host侧和device侧连接的桥梁。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Ascend C __global__ __aicore__ <span class="keyword">void</span> <span class="title">kernel_name</span><span class="params">(argument list)</span></span>;</span><br><span class="line"><span class="function">CUDA __global__ <span class="keyword">void</span> <span class="title">kernel_name</span><span class="params">(argument list)</span></span>;</span><br></pre></td></tr></table></figure>
<h3 id="DaVinci-Core">DaVinci Core</h3>
<h3 id="AI-Core的逻辑架构抽象">AI Core的逻辑架构抽象</h3>
<ul>
<li>
<p>计算单元</p>
<p>AI Core内异步计算过程（指令流）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">标量计算单元:读取指令序列 --&gt; 标量计算单元:发射指令到对应单元 --&gt; 各处理单元:并行执行指令:数据搬运,向量计算,矩阵计算</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>存储单元</p>
<ul>
<li>Local Memory: AI Core上的所有存储，这里的Local本地，指的是AI Core的内部；</li>
<li>Global Memory: 无论是DDR|HBM|L2 级缓存|内存，Global指AI Core外部的存储；</li>
</ul>
</li>
<li>
<p>搬运单元</p>
<p>AI Core内部搬运过程（数据流）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">DMA:数据搬入LocalMem --&gt; 计算单元:数据完成计算,回写LocalMem --&gt; DMA:数据搬出到GlobalMem</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="AI-Core内部并行计算架构抽象">AI Core内部并行计算架构抽象</h3>
<ul>
<li>
<p>计算单元</p>
<p>Scalar计算单元：执行地址计算、循环控制等标量计算工作，并把向量计算、矩阵计算、数据搬运、同步指令发射给对应单元执行</p>
<p>Cube计算单元：负责执行矩阵计算</p>
<p>Vector计算单元：负责执行向量计算</p>
</li>
<li>
<p>搬运单元</p>
<p>负责在Global Memory和Local Memory之间搬运数据</p>
<p>MTE1——数据在AI Core内部的流转</p>
<p>MTE2——数据搬入单元</p>
<p>MTE3——数据搬出单元</p>
</li>
<li>
<p>存储单元</p>
<p>编程对象，数据主体</p>
<p>外部存储：Global Memory</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">(__gm__ uint8 *__restrict__ src_gm, __gm__ <span class="keyword">uint8_t</span> *__restrict__ dst_gm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">uint32_t</span> dataSize = <span class="number">256</span>;</span><br><span class="line">  GlobalTensor&lt;<span class="keyword">int32_t</span>&gt; inputGlobal;<span class="comment">// 类型为int32_t</span></span><br><span class="line">  <span class="comment">// 设置源操作数在Global Memory上的起始地址为src_gm,所占外部存储的大小为256个int32_t</span></span><br><span class="line">  inputGlobal.<span class="built_in">SetGlobalBuffer</span>(<span class="keyword">reinterpret_cast</span>&lt;__gm__ <span class="keyword">int32_t</span> *&gt;(src_gm), dataSize);</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>内部存储：Local Memory</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="class"><span class="keyword">class</span> <span class="title">LocalTensor</span> &#123;</span></span><br><span class="line">  <span class="function">T <span class="title">GetValue</span><span class="params">(<span class="keyword">const</span> <span class="keyword">uint32_t</span> offset)</span> <span class="keyword">const</span></span>; <span class="comment">// 获取LocalTensor中的某个值，返回T类型的立即数。</span></span><br><span class="line">  <span class="comment">// 获取距原LocalTensor起始地址偏移量为offset的新LocalTensor，注意offset不能超过原有LocalTensor的size大小。offset单位为element</span></span><br><span class="line">  LocalTensor <span class="keyword">operator</span>[](<span class="keyword">const</span> <span class="keyword">uint32_t</span> offset) <span class="keyword">const</span>;</span><br><span class="line">  <span class="function"><span class="keyword">uint32_t</span> <span class="title">GetSize</span><span class="params">()</span> <span class="keyword">const</span></span>; <span class="comment">// 获取当前LocalTensor size大小</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LocalTensor指代的是AI Core内部的存储，不同的流水任务之间存在数据依赖，需要进行数据传递。Ascend C中使用Queue队列完成任务之间的数据通信和同步，例如在Compute之前完成CopyIn的数据搬运。</p>
</li>
</ul>
<h3 id="逻辑位置">逻辑位置</h3>
<table>
<thead>
<tr>
<th>TPosition</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>GM</td>
<td>Global Memory，对应AI Core的外部存储</td>
</tr>
<tr>
<td>VECIN</td>
<td>用于向量计算，搬入数据的存放位置，在数据搬入Vector计算单元时使用此位置</td>
</tr>
<tr>
<td>VECOUT</td>
<td>用于向量计算，搬出数据的存放位置，在将Vector计算单元结果搬出时使用此位置</td>
</tr>
<tr>
<td>A1</td>
<td>用于矩阵计算，存放整块A矩阵，可类比CPU多级缓存中的二级缓存</td>
</tr>
<tr>
<td>B1</td>
<td>用于矩阵计算，存放整块B矩阵，可类比CPU多级缓存中的二级缓存</td>
</tr>
<tr>
<td>A2</td>
<td>用于矩阵计算，存放切分后的小块A矩阵，可类比CPU多级缓存中的一级缓存</td>
</tr>
<tr>
<td>B2</td>
<td>用于矩阵计算，存放切分后的小块B矩阵，可类比CPU多级缓存中的一级缓存</td>
</tr>
<tr>
<td>CO1</td>
<td>用于矩阵计算，存放小块结果C矩阵，可理解为Cube Out</td>
</tr>
<tr>
<td>CO2</td>
<td>用于矩阵计算，存放整块结果C矩阵，可理解为Cube Out</td>
</tr>
</tbody>
</table>
<h3 id="开发流程">开发流程</h3>
<p>算子分析：分析算子的数学表达式、输入、输出以及计算逻辑的实现，明确需要调用的Ascend C接口。</p>
<ul>
<li>
<p>明确算子的数学表达式及计算逻辑</p>
<p>Add算子的数学表达式： $$z = x + y$$ ，计算逻辑：输入数据需要先搬入到片上存储，然后使用计算接口完成两个加法运算，得到最终结果，再搬出到外部存储</p>
</li>
<li>
<p>明确输入和输出</p>
<p>Add算子有两个输入： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 与 $$y$$ ，输出为 $$z$$ 。输入数据类型为half，输出数据类型与输入数据类型相同。输入支持固定shape（8，2048），输出shape与输入shape相同。输入数据排布类型为ND。</p>
</li>
<li>
<p>确定核函数名称和参数</p>
<p>自定义核函数名，如add_custom。</p>
</li>
<li>
<p>确定算子实现所需接口</p>
<p>DataCopy实现</p>
<p>Add双目实现</p>
<p>使用到LocalTensor，使用Queue队列管理，会使用到EnQue，DeQue接口。</p>
</li>
</ul>
<p>核函数定义：定义Ascend C算子入口函数</p>
<p>根据编程范式实现算子类：完成核函数的内部实现</p>
<h3 id="编程范式">编程范式</h3>
<p>Ascend C编程范式把算子内部的处理程序，分成多个流水任务（Stage），以张量（Tensor）为数据载体，以队列（Queue）进行任务之间的通信同步，以内存管理模块（Pipe）管理任务间的通信内存。</p>
<h3 id="SPMD模型">SPMD模型</h3>
<p>Ascend C算子编程是SPMD的编程，将需要处理的数据拆分并分布在多个计算核心上运行</p>
<p>多个AI Core共享相同的指令代码，每个核上的运行实例唯一的区别是block_idx不同</p>
<p>block的类似于进程，block_idx就是标识进程唯一性的进程ID，编程中使用函数GetBlockIdx()获取ID</p>
<h3 id="流水任务">流水任务</h3>
<p>单核处理程序中主程序调度的并行任务。在核函数内部，可以通过流水任务实现数据的并行处理来提升性能。</p>
<h3 id="矢量编程流水任务设计">矢量编程流水任务设计</h3>
<p>矢量算子编程范式把算子的实现分为3个基本任务：CopyIn，Compute，CopyOut。</p>
<p>CopyIn，Compute任务间通过VECIN队列inQueueX，inQueueY进行通信和同步，Compute，CopyOut任务间通过VECOUT队列outQueueZ进行通信和同步。</p>
<p>pipe内存管理对象对任务间交互使用到的内存，临时变量使用到的内存统一进行管理。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KernelAdd</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Init</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Process</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">CopyIn</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">Compute</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    	<span class="function">__aicore__ <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">CopyOut</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    	TPipe pipe;</span><br><span class="line">    	TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX, inQueueY;</span><br><span class="line">    	TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    	GlobalTensor&lt;half&gt; xGm, yGm, xGm;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Init-函数实现">Init()函数实现</h3>
<p>使用多核并行计算，需要将数据切片，获取到每个核实际需要处理的在Global Memory上的内存偏移地址.</p>
<p>数据整体长度TOTAL_LENGTH为8 * 2048，平均分配到8个核上运行，每个核上处理的数据大小BLOCK_LENGTH为2048，block_idx为核的逻辑ID，x + block_idx * BLOCK_LENGTH，索引为block_idx的核的输入数据在Global Memory上的内存偏移地址。</p>
<p>对于单核处理数据（2048个数字进行进一步切分，一条向量计算指令，它的计算容量是有限的，Vector是256个字节），可以进行数据切块（Tiling），将数据切分成8块。切分后的每个数据再次切分成BUFFER_NUM=2块，可以开启double buffer,实现流水之间的并行。</p>
<p>单核需要处理的2048个数据切分成16块，每块TILE_LENGTH=128个数据。Pipe为inQueueX分配了BUFFER_NUM块大小为TILE_LENGTH * sizeof(half)个字节的内存块，每个内存块能容纳TILE_LENGTH=128个half类型数据。</p>
<h3 id="CopyIn-函数实现">CopyIn()函数实现</h3>
<h3 id="Compute-函数实现">Compute()函数实现</h3>
<h3 id="CopyOut-函数实现">CopyOut()函数实现</h3>
<h3 id="Host侧算子实现">Host侧算子实现</h3>
<p>host侧算子实现开发包括Tiling实现、Shape推导等函数实现、算子原型注册：</p>
<ol>
<li>
<p>Tiling实现（TilingFunc），计算数据切分过程相关的参数，比如每次计算的数据量大小</p>
<p>（Vector计算单元一次只能处理256Byte，Cube计算单元一次只能处理16 * 16矩阵的计算）</p>
</li>
<li>
<p>Shape推导等函数实现（InferShape），根据算子的输入张量描述、算子逻辑及算子属性，推理出算子的输出张量描述，包括张量的Shape、数据类型及数据排布格式等信息。这样算子在构图准备阶段就可以为所有的张量静态分配内存，避免动态内存分配带来的开销。</p>
</li>
<li>
<p>算子原型注册（OpDef），除了上述函数的开发，还需要进行算子原型定义，原型定义描述了算子的输入输出，属性等信息以及算子在AI处理器上相关实现信息，算子原型注册会关联算子原型定义和上述Tiling实现、Shape推导等函数，将其组合成一个整体。</p>
</li>
<li>
<p>算子类注册（OP_ADD）</p>
</li>
</ol>
<h3 id="Tiling下发">Tiling下发</h3>
<p>大多数情况下，Local Memory的存储，无法完全容纳算子的输入与输出的所有数据，需要每次搬运一部分输入数据进行计算然后搬出，再搬运下一部分输入数据进行计算，直到得到完整的最终结果，这个数据切分，分块计算的过程称之为Tiling实现。</p>
<ul>
<li>每次搬运的那一部分数据块，叫做Tiling块</li>
<li>根据算子中不同输入形状确定搬入基本块大小的相关算法，叫做Tiling算法（或Tiling策略）</li>
<li>承载Tiling策略信息的数据结构叫做Tiling结构体</li>
<li>算子中实现Tiling算法并将Tiling结构体下发给Kernel侧的函数（一般定义在host侧的host实现文件中），叫做Tiling函数（或Tiling Function）</li>
<li>Tiling实现完成后，获取到的Tiling切分算法相关参数，会传递给kernel侧，用于指导并行数据的切分。由于Tiling实现中完成的均为标量计算，AI Core并不擅长，所以我们将其独立出来放在Host侧 CPU上进行。</li>
</ul>
<h3 id="Tiling函数">Tiling函数</h3>
<ul>
<li>定义完Tiling结构体之后，即可着手实现Tiling函数，即尝试根据算子输入输出的shape等信息推算出Tiling信息，保存到Tiling结构体中，下发给Kernel侧。</li>
<li>Tiling函数的入参和出参是同一个对象，即TilingContext对象，Tiling结构体保存在这个对象中，运行时环境会自动将此对象从Host侧传递给Kernel侧。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">获取TilingContext上下文:Tiling函数的入参 --&gt; 通过上下文获取输入输出的Shape信息 --&gt; 根据Shape信息设置TilingData,序列化TilingData并保存至TilingContext --&gt; 设置block_dim --&gt; 设置TilingKey --&gt; 设置workspace_size</span><br></pre></td></tr></table></figure>
<p>根据数据的尺寸设置不同的TilingKey，来选择不同的Tiling策略，同时软件栈在编译的时候会选择对应TilingKey的代码进行编译，节约空间。</p>
<p>将Tiling塞到context中实际上调用的就是<code>tiling.SavetoBuffer</code>，这样device侧就可以拿到tiling信息了。</p>
<h3 id="Kernel侧使用Tiling信息">Kernel侧使用Tiling信息</h3>
<p>kernel侧需要接受Tiling信息时，核函数定义是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ __aicore__ <span class="keyword">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意这里参数的顺序按照“输入、输出、workspace、tiling”的顺序排布，开发者不要调整其顺序。</p>
<p>用GET_TILING_DATA来拆箱，第一个参数“tiling_data”名字随便取。</p>
<p>workspace表示在Global Memory上申请的额外空间。</p>
<h3 id="Shape推导概述">Shape推导概述</h3>
<p>根据输入Tensor得到输出Tensor就可以完成网络的运行，但在实际的网络模型生成过程中，会先进行Tensor Shape以及data type的推导。这样可以让我们在图执行之前，就知道Tensor的数据类型和形状，提前校验其正确性；</p>
<p>同时提前推理出算子的输出张量描述，包括张量的形状，数据类型以及数据排布格式等信息，算子构图准备阶段就可以为所有的张量静态分配内存，避免动态内存分配带来的开销。</p>
<h3 id="计算类API">计算类API</h3>
<p>包括标量计算API、向量计算API、矩阵计算API，分别实现调用Scalar计算单元、Vector计算单元、Cube计算单元执行计算的功能。</p>
<h3 id="CPU域精细调试手段：单步调试——GDB">CPU域精细调试手段：单步调试——GDB</h3>
<p>可使用gdb单步调试算子计算精度。由于cpu调测已转为多进程调试，每个核都会拉起独立的子进程，故gdb需要转换成子进程调试的方式。针对Atlas 推理系列产品、Atlas 训练系列产品，每个核会拉起1个子进程，针对Atlas A2训练系列产品，每个核会拉起3个子进程，1个Cube，2个Vector。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 单独调试一个子进程</span></span><br><span class="line">set follow-fork-mode child </span><br></pre></td></tr></table></figure>
<h3 id="NPU域调试">NPU域调试</h3>
<h4 id="针对标量">针对标量</h4>
<p>在代码中直接编写AscendC::printf(…)来观察数值输出。样例代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AscendC::<span class="built_in">printf</span>(<span class="string">&quot;xLocal size: %d\n&quot;</span>, xLocal.<span class="built_in">GetSize</span>())</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>整个Tensor参与计算</p>
</li>
<li>
<p>Tensor前n个数据计算</p>
</li>
<li>
<p>Tensor高维切分计算</p>
<p>功能灵活的计算API，充分发挥硬件优势，支持对每个操作数的Repeat times(迭代的次数)、Block stride（单次迭代内不同block间地址步长）、Repeat stride（相邻迭代间相同block的地址步长）、Mask（用于控制参与运算的计算单元）的操作。</p>
<ul>
<li>Repeat times(迭代的次数)</li>
</ul>
</li>
</ul>
<h3 id="数据搬运API">数据搬运API</h3>
<p>计算API基于Local Memory数据进行计算，所以数据需要先从Global Memory搬运至Local Memory，再使用计算API完成计算，最后从Local Memory搬出至Global Memory。比如DataCopy接口。</p>
<h3 id="内存管理API">内存管理API</h3>
<p>用于分配管理内存，比如AllocTensor、FreeTensor接口。任务间数据传递使用到的内存统一由<strong>内存管理模块Pipe</strong>进行管理。</p>
<p><strong>Pipe</strong>作为片上内存管理者，通过InitBuffer接口对外提供Queue内存初始化功能，开发者可以通过该接口为指定的<strong>Queue</strong>分配内存。</p>
<p>Queue队列内存初始化完成后，需要使用内存时，通过调用<strong>AllocTensor</strong>来为<strong>LocalTensor</strong>分配内存给<strong>Tensor</strong>，当创建的<strong>LocalTensor</strong>完成相关计算无需再使用时，再调用<strong>FreeTensor</strong>来回收<strong>LocalTensor</strong>的内存。</p>
<p>TQue是队列，对应的TPosition是VECIN，VECOUT，TBuf是缓冲（管理中间变量），对应的TPosition是VECCAL。</p>
<p>TBuf占用的存储空间通过TPipe进行管理，您可以通过<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>接口为TBuf进行内存初始化操作，之后即可通过<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0163.html">Get</a>获取指定长度的Tensor参与计算。</p>
<p><strong>使用<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>为TBuf分配内存和为Queue分配内存有以下差异</strong>：</p>
<ul>
<li>为TBuf分配的内存空间只能参与计算，无法执行Queue队列的入队出队操作。</li>
<li>调用一次内存初始化接口，TPipe只会为TBuf分配一块内存，为Queue队列可以通过参数设置申请多块内存。如果要使用多个临时变量，需要定义多个TBuf数据结构，对每个TBuf数据结构分别调用<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/81RC1/apiref/ascendcopapi/atlasascendc_api_07_0110.html">InitBuffer</a>接口进行内存初始化。</li>
<li>TBuf获取的Tensor无需释放。</li>
</ul>
<h3 id="任务同步API">任务同步API</h3>
<p>完成任务间的通信和同步，比如EnQue、DeQue接口。不同的API指令间有可能存在依赖关系，从硬件架构抽象可知，不同的指令异步并行执行，为了保证不同指令队列间的指令按照正确的逻辑关系执行，需要向不同的组件发送同步指令。同步控制API内部即完成这个发送同步指令的过程，开发者无需关注内部实现逻辑，使用简单的API接口即可完成。</p>
<h3 id="算子调用">算子调用</h3>
<ul>
<li>
<h6 id="Kernel直调">Kernel直调</h6>
<p>NPU侧运行比CPU侧多了Host侧到Device侧拷贝的代码，同时，ACLRT_LAUNCH_KERNEL是异步的，需要aclrtStrem stream来进行管理。</p>
</li>
<li>
<h6 id="AscendCL单算子调用">AscendCL单算子调用</h6>
<ul>
<li>
<p>单算子API执行（aclnn）:基于C语言的API执行算子，直接调用单算子API。多用于大模型训练算子，即整网算子模型较为固定的场景。</p>
<p>aclnnXxxGetWorkspaceSize(const aclTensor *src, …, aclTensor *out，uint64_t workspaceSize，aclOpExecutor **executor);</p>
<p>workspaceSize：工作空间 aclMalloc</p>
</li>
<li>
<p>单算子模型执行：基于图模式执行算子，先编译算子（例如，使用ATC工具将Ascend IR定义的单算子描述文件编译成算子om模型文件），再调用AscendCL接口加载算子模型，最后调用AscendCL接口执行算子。多用于搜广推，整网模型变化较大的场景。</p>
</li>
<li>
<p>Pytorch算子调用</p>
<p>Pytorch的适配流程，主要包括两个步骤：<strong>算子注册分发</strong>和<strong>适配插件实现</strong>。</p>
</li>
</ul>
</li>
</ul>
<h3 id="源码编译-二进制编译">源码编译/二进制编译</h3>
<ul>
<li>
<p>二进制编译</p>
<p>对算子kernel侧实现进行编译，生成描述算子相关文件的json文件*.json和算子二进制 *.o。如果需要直接调用算子二进制，则使用该编译方式</p>
</li>
<li>
<p>源码编译</p>
<p>不对算子kernel侧实现进行编译，保留算子kernel源码文件 *.cpp。该方式可以支持算子的在线编译、通过ATC模型转换的方式编译算子的场景。</p>
</li>
</ul>
<h3 id="形状为（1-660）的half类型输入数据，利用4核完成add计算">形状为（1,660）的half类型输入数据，利用4核完成add计算</h3>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>1</mn><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mo>=</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">1 block = 32 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">1</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">32</span></span></span></span></span></p>
<h4 id="处理步骤1-32字节对齐">处理步骤1: 32字节对齐</h4>
<p>Add的输入shape为（1，660），数据类型为half，当前输入无法对齐到一个block的大小（32B），首先需要进行数据补齐。</p>
<h4 id="处理步骤2：按照核数（本次是4核）进行核间数据拆分">处理步骤2：按照核数（本次是4核）进行核间数据拆分</h4>
<p>上一步将输入数据，补齐为42个32B的数据块，本步骤需要将这些数据分配到4个核上进行计算，每个核上分得的数据块数量不一致。</p>
<h4 id="处理步骤3：根据UB限制进行核内数据分批计算">处理步骤3：根据UB限制进行核内数据分批计算</h4>
<p>针对单核计算，计算核一次能够处理的数据受到UB大小的限制，因此需要根据UB大小将每个核需要处理的数据进行批次拆分。假设本次计算UB大小是1536B。</p>
<h3 id="开发环境">开发环境</h3>
<ul>
<li>
<p>非昇腾AI设备</p>
<p>代码开发、编译等不依赖昇腾设备的开发环境</p>
</li>
<li>
<p>昇腾AI设备</p>
<p>支持代码开发和编译，同时可以运行应用程序或进行训练脚本的迁移、开发&amp;调试</p>
</li>
</ul>
<h3 id="运行环境">运行环境</h3>
<ul>
<li>
<p>昇腾AI设备</p>
<p>支持代码开发和编译，同时可以运行应用程序或进行训练脚本的迁移、开发&amp;调试</p>
</li>
</ul>
<h3 id="CANN相关安装包解读">CANN相关安装包解读</h3>
<p><code>Ascend-cann-toolkit_8.0.RC2.alpha002_linux_aarch64.run</code>其中，<code>Ascend</code>和<code>cann</code>是固定前缀，<code>toolkit</code>代表套件软件包，很多在特定场景下的工具包有单独的命名，如<code>Ascend-cann-nnrt_8.0.RC2.alpha002_linux_aarch64.run</code>，<code>nnrt</code>代表推理引擎，其他<code>nnae</code>、<code>kernels</code>代表深度学习引擎软件包和算子二进制安装包。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://itachicheng.github.io">ChengQiang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://itachicheng.github.io/Ascend/">https://itachicheng.github.io/Ascend/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Diffusion-Model/" title="Diffusion-Model"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">Diffusion-Model</div></div></a></div><div class="next-post pull-right"><a href="/Personal-Keyboard-Layout-Optimization/" title="Personal-Keyboard-Layout-Optimization.md"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">Personal-Keyboard-Layout-Optimization.md</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/loopy2.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ChengQiang</div><div class="author-info__description">The only way to do great work is to love what you do. Keep looking, and don't settle.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/itachiCheng"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Host%E4%B8%8EDevice"><span class="toc-number">1.</span> <span class="toc-text">Host与Device</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-number">2.</span> <span class="toc-text">核函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DaVinci-Core"><span class="toc-number">3.</span> <span class="toc-text">DaVinci Core</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AI-Core%E7%9A%84%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E6%8A%BD%E8%B1%A1"><span class="toc-number">4.</span> <span class="toc-text">AI Core的逻辑架构抽象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AI-Core%E5%86%85%E9%83%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84%E6%8A%BD%E8%B1%A1"><span class="toc-number">5.</span> <span class="toc-text">AI Core内部并行计算架构抽象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E4%BD%8D%E7%BD%AE"><span class="toc-number">6.</span> <span class="toc-text">逻辑位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="toc-number">7.</span> <span class="toc-text">开发流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F"><span class="toc-number">8.</span> <span class="toc-text">编程范式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SPMD%E6%A8%A1%E5%9E%8B"><span class="toc-number">9.</span> <span class="toc-text">SPMD模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E6%B0%B4%E4%BB%BB%E5%8A%A1"><span class="toc-number">10.</span> <span class="toc-text">流水任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A2%E9%87%8F%E7%BC%96%E7%A8%8B%E6%B5%81%E6%B0%B4%E4%BB%BB%E5%8A%A1%E8%AE%BE%E8%AE%A1"><span class="toc-number">11.</span> <span class="toc-text">矢量编程流水任务设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Init-%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0"><span class="toc-number">12.</span> <span class="toc-text">Init()函数实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CopyIn-%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0"><span class="toc-number">13.</span> <span class="toc-text">CopyIn()函数实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Compute-%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0"><span class="toc-number">14.</span> <span class="toc-text">Compute()函数实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CopyOut-%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0"><span class="toc-number">15.</span> <span class="toc-text">CopyOut()函数实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Host%E4%BE%A7%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0"><span class="toc-number">16.</span> <span class="toc-text">Host侧算子实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiling%E4%B8%8B%E5%8F%91"><span class="toc-number">17.</span> <span class="toc-text">Tiling下发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiling%E5%87%BD%E6%95%B0"><span class="toc-number">18.</span> <span class="toc-text">Tiling函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kernel%E4%BE%A7%E4%BD%BF%E7%94%A8Tiling%E4%BF%A1%E6%81%AF"><span class="toc-number">19.</span> <span class="toc-text">Kernel侧使用Tiling信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shape%E6%8E%A8%E5%AF%BC%E6%A6%82%E8%BF%B0"><span class="toc-number">20.</span> <span class="toc-text">Shape推导概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%B1%BBAPI"><span class="toc-number">21.</span> <span class="toc-text">计算类API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU%E5%9F%9F%E7%B2%BE%E7%BB%86%E8%B0%83%E8%AF%95%E6%89%8B%E6%AE%B5%EF%BC%9A%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95%E2%80%94%E2%80%94GDB"><span class="toc-number">22.</span> <span class="toc-text">CPU域精细调试手段：单步调试——GDB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NPU%E5%9F%9F%E8%B0%83%E8%AF%95"><span class="toc-number">23.</span> <span class="toc-text">NPU域调试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%92%88%E5%AF%B9%E6%A0%87%E9%87%8F"><span class="toc-number">23.1.</span> <span class="toc-text">针对标量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%90%AC%E8%BF%90API"><span class="toc-number">24.</span> <span class="toc-text">数据搬运API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86API"><span class="toc-number">25.</span> <span class="toc-text">内存管理API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E5%90%8C%E6%AD%A5API"><span class="toc-number">26.</span> <span class="toc-text">任务同步API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E8%B0%83%E7%94%A8"><span class="toc-number">27.</span> <span class="toc-text">算子调用</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Kernel%E7%9B%B4%E8%B0%83"><span class="toc-number">27.0.0.1.</span> <span class="toc-text">Kernel直调</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#AscendCL%E5%8D%95%E7%AE%97%E5%AD%90%E8%B0%83%E7%94%A8"><span class="toc-number">27.0.0.2.</span> <span class="toc-text">AscendCL单算子调用</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91-%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91"><span class="toc-number">28.</span> <span class="toc-text">源码编译&#x2F;二进制编译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%A2%E7%8A%B6%E4%B8%BA%EF%BC%881-660%EF%BC%89%E7%9A%84half%E7%B1%BB%E5%9E%8B%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%88%A9%E7%94%A84%E6%A0%B8%E5%AE%8C%E6%88%90add%E8%AE%A1%E7%AE%97"><span class="toc-number">29.</span> <span class="toc-text">形状为（1,660）的half类型输入数据，利用4核完成add计算</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%AD%A5%E9%AA%A41-32%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90"><span class="toc-number">29.1.</span> <span class="toc-text">处理步骤1: 32字节对齐</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%AD%A5%E9%AA%A42%EF%BC%9A%E6%8C%89%E7%85%A7%E6%A0%B8%E6%95%B0%EF%BC%88%E6%9C%AC%E6%AC%A1%E6%98%AF4%E6%A0%B8%EF%BC%89%E8%BF%9B%E8%A1%8C%E6%A0%B8%E9%97%B4%E6%95%B0%E6%8D%AE%E6%8B%86%E5%88%86"><span class="toc-number">29.2.</span> <span class="toc-text">处理步骤2：按照核数（本次是4核）进行核间数据拆分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%AD%A5%E9%AA%A43%EF%BC%9A%E6%A0%B9%E6%8D%AEUB%E9%99%90%E5%88%B6%E8%BF%9B%E8%A1%8C%E6%A0%B8%E5%86%85%E6%95%B0%E6%8D%AE%E5%88%86%E6%89%B9%E8%AE%A1%E7%AE%97"><span class="toc-number">29.3.</span> <span class="toc-text">处理步骤3：根据UB限制进行核内数据分批计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83"><span class="toc-number">30.</span> <span class="toc-text">开发环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">31.</span> <span class="toc-text">运行环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CANN%E7%9B%B8%E5%85%B3%E5%AE%89%E8%A3%85%E5%8C%85%E8%A7%A3%E8%AF%BB"><span class="toc-number">32.</span> <span class="toc-text">CANN相关安装包解读</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Depth-First-Search/" title="Depth-First-Search"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Depth-First-Search"/></a><div class="content"><a class="title" href="/Depth-First-Search/" title="Depth-First-Search">Depth-First-Search</a><time datetime="2025-08-05T01:46:24.000Z" title="Created 2025-08-05 11:46:24">2025-08-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Diffusion-Model/" title="Diffusion-Model"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Diffusion-Model"/></a><div class="content"><a class="title" href="/Diffusion-Model/" title="Diffusion-Model">Diffusion-Model</a><time datetime="2025-06-06T14:39:51.000Z" title="Created 2025-06-07 00:39:51">2025-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Ascend/" title="Ascend"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ascend"/></a><div class="content"><a class="title" href="/Ascend/" title="Ascend">Ascend</a><time datetime="2025-05-29T15:40:00.000Z" title="Created 2025-05-30 01:40:00">2025-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Personal-Keyboard-Layout-Optimization/" title="Personal-Keyboard-Layout-Optimization.md"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Personal-Keyboard-Layout-Optimization.md"/></a><div class="content"><a class="title" href="/Personal-Keyboard-Layout-Optimization/" title="Personal-Keyboard-Layout-Optimization.md">Personal-Keyboard-Layout-Optimization.md</a><time datetime="2025-03-23T07:46:19.000Z" title="Created 2025-03-23 18:46:19">2025-03-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Jupyter-Config/" title="Jupyter-Config"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Jupyter-Config"/></a><div class="content"><a class="title" href="/Jupyter-Config/" title="Jupyter-Config">Jupyter-Config</a><time datetime="2025-02-11T02:42:55.000Z" title="Created 2025-02-11 13:42:55">2025-02-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By ChengQiang</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.14.0-b3"></script><script src="/js/main.js?v=4.14.0-b3"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.35/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>